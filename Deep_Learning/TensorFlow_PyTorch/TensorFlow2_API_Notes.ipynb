{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6871ac25",
   "metadata": {},
   "source": [
    "# I - The TensorFlow 2 API - Notes\n",
    "### 2022/06/16, Ahmed J Zerouali\n",
    "### Updated: 2022/07/06\n",
    "\n",
    "## 1) Introduction\n",
    "This notebook gathers some fundamentals of the TF2 API, following S Ravichandiran's \"Deep RL with Python\" Ch. 8. The main objective is to record a high level overview of this library and get a working understanding of its functioning.\n",
    "\n",
    "**Comment:** Ravichandiran's presentation is not how I would do it. I'll follow him first and then make the appropriate changes to these notes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96e4b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba8863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16c2ad2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\Scripts\\matplotlib-script.py\", line 10, in <module>\n",
      "    sys.exit(plotting._matplotlib())\n",
      "AttributeError: module 'pandas.plotting' has no attribute '_matplotlib'\n"
     ]
    }
   ],
   "source": [
    "!matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac823cdc",
   "metadata": {},
   "source": [
    "A word of caution. Ravichandiran first explains how TF1.x worked, and later focuses on TF2. For example, the \"Hello TensorFlow\" example on p.320 is applicable to version 1:\n",
    "\n",
    "            hello = tf.constant(\"Hello TensorFlow\")\n",
    "            sess = tf.Session()\n",
    "            print(sess.run(hello))\n",
    "            \n",
    "This code returns an error in TF2, since the Session() module has been moved to *compat.v1*. See: https://www.tensorflow.org/api_docs/python/tf/compat/v1/Session.\n",
    "\n",
    "One way to reproduce the code above in TF2.x is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9e9151a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello TensorFlow 2'\n"
     ]
    }
   ],
   "source": [
    "# We'll clarify the meaning of this call later (see graph mode and eager execution below)\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "tf_hello = tf.constant(\"Hello TensorFlow 2\")\n",
    "test_session = tf.compat.v1.Session()\n",
    "print(test_session.run(tf_hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58a71da7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Session in module tensorflow.python.client.session:\n",
      "\n",
      "class Session(BaseSession)\n",
      " |  Session(target='', graph=None, config=None)\n",
      " |  \n",
      " |  A class for running TensorFlow operations.\n",
      " |  \n",
      " |  A `Session` object encapsulates the environment in which `Operation`\n",
      " |  objects are executed, and `Tensor` objects are evaluated. For\n",
      " |  example:\n",
      " |  \n",
      " |  ```python\n",
      " |  tf.compat.v1.disable_eager_execution() # need to disable eager in TF2.x\n",
      " |  # Build a graph.\n",
      " |  a = tf.constant(5.0)\n",
      " |  b = tf.constant(6.0)\n",
      " |  c = a * b\n",
      " |  \n",
      " |  # Launch the graph in a session.\n",
      " |  sess = tf.compat.v1.Session()\n",
      " |  \n",
      " |  # Evaluate the tensor `c`.\n",
      " |  print(sess.run(c)) # prints 30.0\n",
      " |  ```\n",
      " |  \n",
      " |  A session may own resources, such as\n",
      " |  `tf.Variable`, `tf.queue.QueueBase`,\n",
      " |  and `tf.compat.v1.ReaderBase`. It is important to release\n",
      " |  these resources when they are no longer required. To do this, either\n",
      " |  invoke the `tf.Session.close` method on the session, or use\n",
      " |  the session as a context manager. The following two examples are\n",
      " |  equivalent:\n",
      " |  \n",
      " |  ```python\n",
      " |  # Using the `close()` method.\n",
      " |  sess = tf.compat.v1.Session()\n",
      " |  sess.run(...)\n",
      " |  sess.close()\n",
      " |  \n",
      " |  # Using the context manager.\n",
      " |  with tf.compat.v1.Session() as sess:\n",
      " |    sess.run(...)\n",
      " |  ```\n",
      " |  \n",
      " |  The\n",
      " |  [`ConfigProto`](https://www.tensorflow.org/code/tensorflow/core/protobuf/config.proto)\n",
      " |  protocol buffer exposes various configuration options for a\n",
      " |  session. For example, to create a session that uses soft constraints\n",
      " |  for device placement, and log the resulting placement decisions,\n",
      " |  create a session as follows:\n",
      " |  \n",
      " |  ```python\n",
      " |  # Launch the graph in a session that allows soft device placement and\n",
      " |  # logs the placement decisions.\n",
      " |  sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(\n",
      " |      allow_soft_placement=True,\n",
      " |      log_device_placement=True))\n",
      " |  ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Session\n",
      " |      BaseSession\n",
      " |      SessionInterface\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __enter__(self)\n",
      " |  \n",
      " |  __exit__(self, exec_type, exec_value, exec_tb)\n",
      " |  \n",
      " |  __init__(self, target='', graph=None, config=None)\n",
      " |      Creates a new TensorFlow session.\n",
      " |      \n",
      " |      If no `graph` argument is specified when constructing the session,\n",
      " |      the default graph will be launched in the session. If you are\n",
      " |      using more than one graph (created with `tf.Graph()`) in the same\n",
      " |      process, you will have to use different sessions for each graph,\n",
      " |      but each graph can be used in multiple sessions. In this case, it\n",
      " |      is often clearer to pass the graph to be launched explicitly to\n",
      " |      the session constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |        target: (Optional.) The execution engine to connect to. Defaults to using\n",
      " |          an in-process engine. See\n",
      " |          [Distributed TensorFlow](https://tensorflow.org/deploy/distributed) for\n",
      " |            more examples.\n",
      " |        graph: (Optional.) The `Graph` to be launched (described above).\n",
      " |        config: (Optional.) A\n",
      " |          [`ConfigProto`](https://www.tensorflow.org/code/tensorflow/core/protobuf/config.proto)\n",
      " |            protocol buffer with configuration options for the session.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  reset(target, containers=None, config=None)\n",
      " |      Resets resource containers on `target`, and close all connected sessions.\n",
      " |      \n",
      " |      A resource container is distributed across all workers in the\n",
      " |      same cluster as `target`.  When a resource container on `target`\n",
      " |      is reset, resources associated with that container will be cleared.\n",
      " |      In particular, all Variables in the container will become undefined:\n",
      " |      they lose their values and shapes.\n",
      " |      \n",
      " |      NOTE:\n",
      " |      (i) reset() is currently only implemented for distributed sessions.\n",
      " |      (ii) Any sessions on the master named by `target` will be closed.\n",
      " |      \n",
      " |      If no resource containers are provided, all containers are reset.\n",
      " |      \n",
      " |      Args:\n",
      " |        target: The execution engine to connect to.\n",
      " |        containers: A list of resource container name strings, or `None` if all of\n",
      " |          all the containers are to be reset.\n",
      " |        config: (Optional.) Protocol buffer with configuration options.\n",
      " |      \n",
      " |      Raises:\n",
      " |        tf.errors.OpError: Or one of its subclasses if an error occurs while\n",
      " |          resetting containers.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseSession:\n",
      " |  \n",
      " |  __del__(self)\n",
      " |  \n",
      " |  as_default(self)\n",
      " |      Returns a context manager that makes this object the default session.\n",
      " |      \n",
      " |      Use with the `with` keyword to specify that calls to\n",
      " |      `tf.Operation.run` or `tf.Tensor.eval` should be executed in\n",
      " |      this session.\n",
      " |      \n",
      " |      ```python\n",
      " |      c = tf.constant(..)\n",
      " |      sess = tf.compat.v1.Session()\n",
      " |      \n",
      " |      with sess.as_default():\n",
      " |        assert tf.compat.v1.get_default_session() is sess\n",
      " |        print(c.eval())\n",
      " |      ```\n",
      " |      \n",
      " |      To get the current default session, use `tf.compat.v1.get_default_session`.\n",
      " |      \n",
      " |      *N.B.* The `as_default` context manager *does not* close the\n",
      " |      session when you exit the context, and you must close the session\n",
      " |      explicitly.\n",
      " |      \n",
      " |      ```python\n",
      " |      c = tf.constant(...)\n",
      " |      sess = tf.compat.v1.Session()\n",
      " |      with sess.as_default():\n",
      " |        print(c.eval())\n",
      " |      # ...\n",
      " |      with sess.as_default():\n",
      " |        print(c.eval())\n",
      " |      \n",
      " |      sess.close()\n",
      " |      ```\n",
      " |      \n",
      " |      Alternatively, you can use `with tf.compat.v1.Session():` to create a\n",
      " |      session that is automatically closed on exiting the context,\n",
      " |      including when an uncaught exception is raised.\n",
      " |      \n",
      " |      *N.B.* The default session is a property of the current thread. If you\n",
      " |      create a new thread, and wish to use the default session in that\n",
      " |      thread, you must explicitly add a `with sess.as_default():` in that\n",
      " |      thread's function.\n",
      " |      \n",
      " |      *N.B.* Entering a `with sess.as_default():` block does not affect\n",
      " |      the current default graph. If you are using multiple graphs, and\n",
      " |      `sess.graph` is different from the value of\n",
      " |      `tf.compat.v1.get_default_graph`, you must explicitly enter a\n",
      " |      `with sess.graph.as_default():` block to make `sess.graph` the default\n",
      " |      graph.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A context manager using this session as the default session.\n",
      " |  \n",
      " |  close(self)\n",
      " |      Closes this session.\n",
      " |      \n",
      " |      Calling this method frees all resources associated with the session.\n",
      " |      \n",
      " |      Raises:\n",
      " |        tf.errors.OpError: Or one of its subclasses if an error occurs while\n",
      " |          closing the TensorFlow session.\n",
      " |  \n",
      " |  list_devices(self)\n",
      " |      Lists available devices in this session.\n",
      " |      \n",
      " |      ```python\n",
      " |      devices = sess.list_devices()\n",
      " |      for d in devices:\n",
      " |        print(d.name)\n",
      " |      ```\n",
      " |      \n",
      " |      Where:\n",
      " |        Each element in the list has the following properties\n",
      " |        name: A string with the full name of the device. ex:\n",
      " |            `/job:worker/replica:0/task:3/device:CPU:0`\n",
      " |        device_type: The type of the device (e.g. `CPU`, `GPU`, `TPU`.)\n",
      " |        memory_limit: The maximum amount of memory available on the device.\n",
      " |            Note: depending on the device, it is possible the usable memory could\n",
      " |            be substantially less.\n",
      " |      \n",
      " |      Raises:\n",
      " |        tf.errors.OpError: If it encounters an error (e.g. session is in an\n",
      " |        invalid state, or network errors occur).\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of devices in the session.\n",
      " |  \n",
      " |  make_callable(self, fetches, feed_list=None, accept_options=False)\n",
      " |      Returns a Python callable that runs a particular step.\n",
      " |      \n",
      " |      The returned callable will take `len(feed_list)` arguments whose types\n",
      " |      must be compatible feed values for the respective elements of `feed_list`.\n",
      " |      For example, if element `i` of `feed_list` is a `tf.Tensor`, the `i`th\n",
      " |      argument to the returned callable must be a numpy ndarray (or something\n",
      " |      convertible to an ndarray) with matching element type and shape. See\n",
      " |      `tf.Session.run` for details of the allowable feed key and value types.\n",
      " |      \n",
      " |      The returned callable will have the same return type as\n",
      " |      `tf.Session.run(fetches, ...)`. For example, if `fetches` is a `tf.Tensor`,\n",
      " |      the callable will return a numpy ndarray; if `fetches` is a `tf.Operation`,\n",
      " |      it will return `None`.\n",
      " |      \n",
      " |      Args:\n",
      " |        fetches: A value or list of values to fetch. See `tf.Session.run` for\n",
      " |          details of the allowable fetch types.\n",
      " |        feed_list: (Optional.) A list of `feed_dict` keys. See `tf.Session.run`\n",
      " |          for details of the allowable feed key types.\n",
      " |        accept_options: (Optional.) If `True`, the returned `Callable` will be\n",
      " |          able to accept `tf.compat.v1.RunOptions` and `tf.compat.v1.RunMetadata`\n",
      " |          as optional keyword arguments `options` and `run_metadata`,\n",
      " |          respectively, with the same syntax and semantics as `tf.Session.run`,\n",
      " |          which is useful for certain use cases (profiling and debugging) but will\n",
      " |          result in measurable slowdown of the `Callable`'s\n",
      " |          performance. Default: `False`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A function that when called will execute the step defined by\n",
      " |        `feed_list` and `fetches` in this session.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If `fetches` or `feed_list` cannot be interpreted\n",
      " |          as arguments to `tf.Session.run`.\n",
      " |  \n",
      " |  partial_run(self, handle, fetches, feed_dict=None)\n",
      " |      Continues the execution with more feeds and fetches.\n",
      " |      \n",
      " |      This is EXPERIMENTAL and subject to change.\n",
      " |      \n",
      " |      To use partial execution, a user first calls `partial_run_setup()` and\n",
      " |      then a sequence of `partial_run()`. `partial_run_setup` specifies the\n",
      " |      list of feeds and fetches that will be used in the subsequent\n",
      " |      `partial_run` calls.\n",
      " |      \n",
      " |      The optional `feed_dict` argument allows the caller to override\n",
      " |      the value of tensors in the graph. See run() for more information.\n",
      " |      \n",
      " |      Below is a simple example:\n",
      " |      \n",
      " |      ```python\n",
      " |      a = array_ops.placeholder(dtypes.float32, shape=[])\n",
      " |      b = array_ops.placeholder(dtypes.float32, shape=[])\n",
      " |      c = array_ops.placeholder(dtypes.float32, shape=[])\n",
      " |      r1 = math_ops.add(a, b)\n",
      " |      r2 = math_ops.multiply(r1, c)\n",
      " |      \n",
      " |      h = sess.partial_run_setup([r1, r2], [a, b, c])\n",
      " |      res = sess.partial_run(h, r1, feed_dict={a: 1, b: 2})\n",
      " |      res = sess.partial_run(h, r2, feed_dict={c: res})\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        handle: A handle for a sequence of partial runs.\n",
      " |        fetches: A single graph element, a list of graph elements, or a dictionary\n",
      " |          whose values are graph elements or lists of graph elements (see\n",
      " |          documentation for `run`).\n",
      " |        feed_dict: A dictionary that maps graph elements to values (described\n",
      " |          above).\n",
      " |      \n",
      " |      Returns:\n",
      " |        Either a single value if `fetches` is a single graph element, or\n",
      " |        a list of values if `fetches` is a list, or a dictionary with the\n",
      " |        same keys as `fetches` if that is a dictionary\n",
      " |        (see documentation for `run`).\n",
      " |      \n",
      " |      Raises:\n",
      " |        tf.errors.OpError: Or one of its subclasses on error.\n",
      " |  \n",
      " |  partial_run_setup(self, fetches, feeds=None)\n",
      " |      Sets up a graph with feeds and fetches for partial run.\n",
      " |      \n",
      " |      This is EXPERIMENTAL and subject to change.\n",
      " |      \n",
      " |      Note that contrary to `run`, `feeds` only specifies the graph elements.\n",
      " |      The tensors will be supplied by the subsequent `partial_run` calls.\n",
      " |      \n",
      " |      Args:\n",
      " |        fetches: A single graph element, or a list of graph elements.\n",
      " |        feeds: A single graph element, or a list of graph elements.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A handle for partial run.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If this `Session` is in an invalid state (e.g. has been\n",
      " |          closed).\n",
      " |        TypeError: If `fetches` or `feed_dict` keys are of an inappropriate type.\n",
      " |        tf.errors.OpError: Or one of its subclasses if a TensorFlow error happens.\n",
      " |  \n",
      " |  run(self, fetches, feed_dict=None, options=None, run_metadata=None)\n",
      " |      Runs operations and evaluates tensors in `fetches`.\n",
      " |      \n",
      " |      This method runs one \"step\" of TensorFlow computation, by\n",
      " |      running the necessary graph fragment to execute every `Operation`\n",
      " |      and evaluate every `Tensor` in `fetches`, substituting the values in\n",
      " |      `feed_dict` for the corresponding input values.\n",
      " |      \n",
      " |      The `fetches` argument may be a single graph element, or an arbitrarily\n",
      " |      nested list, tuple, namedtuple, dict, or OrderedDict containing graph\n",
      " |      elements at its leaves.  A graph element can be one of the following types:\n",
      " |      \n",
      " |      * A `tf.Operation`.\n",
      " |        The corresponding fetched value will be `None`.\n",
      " |      * A `tf.Tensor`.\n",
      " |        The corresponding fetched value will be a numpy ndarray containing the\n",
      " |        value of that tensor.\n",
      " |      * A `tf.sparse.SparseTensor`.\n",
      " |        The corresponding fetched value will be a\n",
      " |        `tf.compat.v1.SparseTensorValue`\n",
      " |        containing the value of that sparse tensor.\n",
      " |      * A `get_tensor_handle` op.  The corresponding fetched value will be a\n",
      " |        numpy ndarray containing the handle of that tensor.\n",
      " |      * A `string` which is the name of a tensor or operation in the graph.\n",
      " |      \n",
      " |      The value returned by `run()` has the same shape as the `fetches` argument,\n",
      " |      where the leaves are replaced by the corresponding values returned by\n",
      " |      TensorFlow.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |         a = tf.constant([10, 20])\n",
      " |         b = tf.constant([1.0, 2.0])\n",
      " |         # 'fetches' can be a singleton\n",
      " |         v = session.run(a)\n",
      " |         # v is the numpy array [10, 20]\n",
      " |         # 'fetches' can be a list.\n",
      " |         v = session.run([a, b])\n",
      " |         # v is a Python list with 2 numpy arrays: the 1-D array [10, 20] and the\n",
      " |         # 1-D array [1.0, 2.0]\n",
      " |         # 'fetches' can be arbitrary lists, tuples, namedtuple, dicts:\n",
      " |         MyData = collections.namedtuple('MyData', ['a', 'b'])\n",
      " |         v = session.run({'k1': MyData(a, b), 'k2': [b, a]})\n",
      " |         # v is a dict with\n",
      " |         # v['k1'] is a MyData namedtuple with 'a' (the numpy array [10, 20]) and\n",
      " |         # 'b' (the numpy array [1.0, 2.0])\n",
      " |         # v['k2'] is a list with the numpy array [1.0, 2.0] and the numpy array\n",
      " |         # [10, 20].\n",
      " |      ```\n",
      " |      \n",
      " |      The optional `feed_dict` argument allows the caller to override\n",
      " |      the value of tensors in the graph. Each key in `feed_dict` can be\n",
      " |      one of the following types:\n",
      " |      \n",
      " |      * If the key is a `tf.Tensor`, the\n",
      " |        value may be a Python scalar, string, list, or numpy ndarray\n",
      " |        that can be converted to the same `dtype` as that\n",
      " |        tensor. Additionally, if the key is a\n",
      " |        `tf.compat.v1.placeholder`, the shape of\n",
      " |        the value will be checked for compatibility with the placeholder.\n",
      " |      * If the key is a\n",
      " |        `tf.sparse.SparseTensor`,\n",
      " |        the value should be a\n",
      " |        `tf.compat.v1.SparseTensorValue`.\n",
      " |      * If the key is a nested tuple of `Tensor`s or `SparseTensor`s, the value\n",
      " |        should be a nested tuple with the same structure that maps to their\n",
      " |        corresponding values as above.\n",
      " |      \n",
      " |      Each value in `feed_dict` must be convertible to a numpy array of the dtype\n",
      " |      of the corresponding key.\n",
      " |      \n",
      " |      The optional `options` argument expects a [`RunOptions`] proto. The options\n",
      " |      allow controlling the behavior of this particular step (e.g. turning tracing\n",
      " |      on).\n",
      " |      \n",
      " |      The optional `run_metadata` argument expects a [`RunMetadata`] proto. When\n",
      " |      appropriate, the non-Tensor output of this step will be collected there. For\n",
      " |      example, when users turn on tracing in `options`, the profiled info will be\n",
      " |      collected into this argument and passed back.\n",
      " |      \n",
      " |      Args:\n",
      " |        fetches: A single graph element, a list of graph elements, or a dictionary\n",
      " |          whose values are graph elements or lists of graph elements (described\n",
      " |          above).\n",
      " |        feed_dict: A dictionary that maps graph elements to values (described\n",
      " |          above).\n",
      " |        options: A [`RunOptions`] protocol buffer\n",
      " |        run_metadata: A [`RunMetadata`] protocol buffer\n",
      " |      \n",
      " |      Returns:\n",
      " |        Either a single value if `fetches` is a single graph element, or\n",
      " |        a list of values if `fetches` is a list, or a dictionary with the\n",
      " |        same keys as `fetches` if that is a dictionary (described above).\n",
      " |        Order in which `fetches` operations are evaluated inside the call\n",
      " |        is undefined.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If this `Session` is in an invalid state (e.g. has been\n",
      " |          closed).\n",
      " |        TypeError: If `fetches` or `feed_dict` keys are of an inappropriate type.\n",
      " |        ValueError: If `fetches` or `feed_dict` keys are invalid or refer to a\n",
      " |          `Tensor` that doesn't exist.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseSession:\n",
      " |  \n",
      " |  graph\n",
      " |      The graph that was launched in this session.\n",
      " |  \n",
      " |  graph_def\n",
      " |      A serializable version of the underlying TensorFlow graph.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A graph_pb2.GraphDef proto containing nodes for all of the Operations in\n",
      " |        the underlying TensorFlow graph.\n",
      " |  \n",
      " |  sess_str\n",
      " |      The TensorFlow process to which this session will connect.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from SessionInterface:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.compat.v1.Session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a817d05",
   "metadata": {},
   "source": [
    "**Comment:** We will work with TF1.x for a bit starting this point..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90eb8afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diable eager execution\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceca72ab",
   "metadata": {},
   "source": [
    "## 2) Graphs and sessions\n",
    "\n",
    "\n",
    "### 2.a - Computational graphs\n",
    "\n",
    "Computational graphs are the foundational structure of TF1. The image below illustrates the computational graph of the function $f(x) = \\text{ReLU}(Wx+b)$:\n",
    "\n",
    "<img src = \"Figures/TF_Graphs_Ravichandiran_Fig_8.1.png\" style = \"height: 320px;\" >\n",
    "\n",
    "In these graphs:\n",
    "* *Nodes* are mathematical operations;\n",
    "* *Edges* are tensors;\n",
    "* There are *direct dependencies*, when the output of a node depends on that of another node;\n",
    "* *Indirect* dependencies when the output of a node doesn't depend on that of another node.\n",
    "\n",
    "**Questions/Comments:** \n",
    "\n",
    "* The graphs give an abstract representation of neural networks. More generally, TensorFlow always builds a computational graph of the tensors and operations used. These are stored in \"working_directory/graphs\". Later, we'll see how to access these through TensorBoard.\n",
    "* The dependencies are important for resource allocation. When building a computational graph, the independent dependencies are distributed accross the available resources to reduce computation time (if I understand well, the goal is to paralellize the computations).\n",
    "\n",
    "By default, every computation in TF1 is represented by such a graph, and creating a session builds a default graph. We'll get back to this point in the next section, in the meantime, here is how one creates a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7679908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple graph\n",
    "a = tf.constant(5,name = \"a\")\n",
    "b = tf.multiply(a, 3, name = \"b\")\n",
    "graph_0 = tf.compat.v1.Graph()\n",
    "\n",
    "# Set this graph as default\n",
    "with graph_0.as_default():\n",
    "    z = tf.add(a,b, name=\"Add\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5d552e",
   "metadata": {},
   "source": [
    "The cell above creates the following graph:\n",
    "\n",
    "<img src = \"Figures/TF_Graphs_Graph-Example_1.png\" style = \"height: 160px;\" >\n",
    "\n",
    "To see it however, it has to be run in a session. To summarize this part:\n",
    "\n",
    "* The **Graph()** class is the foundational computational structure of TF1. In TF2, it is instantiated via **tf.compat.v1.Graph()**.\n",
    "* Most of the old modules and functions of TF1 have been moved to **tf.compat.v1**.\n",
    "* The basic operations (*multiply()*, *add()*) are directly called from \"tf\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c103d4cf",
   "metadata": {},
   "source": [
    "### Disgression: The with statement\n",
    "\n",
    "The *with* statement is used a lot in TensoFlow, and falls within the realm of context managers in Python. The little that we record here is taken from:\n",
    "\n",
    "https://realpython.com/python-with-statement/#the-with-statement-approach\n",
    "\n",
    "The *with* statement creates a runtime context to manage a set of instructions. The general syntax is as follows:\n",
    "\n",
    "            with expression as target_var:\n",
    "                do_something(target_var)\n",
    "                \n",
    "When running into such a block of code, Python does the following:\n",
    "\n",
    "1) Call *expression* to obtain a context manager.\n",
    "\n",
    "2) Store the context manager’s .__enter__() and .__exit__() methods for later use.\n",
    "\n",
    "3) Call .__enter__() on the context manager and bind its return value to *target_var* if provided.\n",
    "\n",
    "4) Execute the *with* code block. \n",
    "\n",
    "5) Call .__exit__() on the context manager when the *with* code block finishes.\n",
    "\n",
    "A good idea is to compare this with the code:\n",
    "\n",
    "            with open(\"hello.txt\", mode=\"w\") as file:\n",
    "                file.write(\"Hello, World!\")\n",
    "                \n",
    "Once the interpreter calls .__**exit**__(), there is also some cleanup being executed such as closing the file. More generally, the interpreter releases the acquired resources upon exiting the *with* code block.\n",
    "\n",
    "The main advantages for using *with* are that it:\n",
    "\n",
    "* Makes resource management safer than its equivalent try … finally statements.\n",
    "* Encapsulates standard uses of *try … finally* statements in context managers.\n",
    "* Allows reusing the code that automatically manages the setup and teardown phases of a given operation.\n",
    "* Helps avoid resource leaks\n",
    "\n",
    "**Comment:** I need to read more about this. I don't fully get it, other than resource management for the particular case of computation-heavy TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b6dae3",
   "metadata": {},
   "source": [
    "### 2.b - Sessions\n",
    "\n",
    "We saw how to build simple computational graphs with TensorFlow. Now to execute a graph we use a TensorFlow session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1964ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97b52f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ebdfd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4885b370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "566264bc",
   "metadata": {},
   "source": [
    "# II - MNIST classification with TensorFlow\n",
    "### 22/06/23, A.J. Zerouali\n",
    "### Updated: 22/06/27\n",
    "\n",
    "The famous deep learning with CNN exercise. The purpose of this part is to build the neural net for the classification of these handwritten digits with both of the TF1 API and TF2/Keras. I'm following Ravichandiran Ch.8 here, starting p.330.\n",
    "\n",
    "I'm making separate imports here (next cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f988ed3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# This will kill the warnings with pink background\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fd04d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6029cd8",
   "metadata": {},
   "source": [
    "## 1) Loading MNIST\n",
    "\n",
    "Now we import the MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50ad721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_keras = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e3170d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 18s 2us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist_keras.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91a09111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8e519cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3236b54a",
   "metadata": {},
   "source": [
    "Let's look at one image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "334dc959",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = X_train[10,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "673622c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd915152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x258c0fab0d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c4e24c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc6ed814",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1_flat = img_1.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92664bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_1_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "480bfffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x258c0f3c430>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_1_flat.reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ed6663",
   "metadata": {},
   "source": [
    "I will save a smaller dataset of flattened images. Note that the 60k test images take-up 45MB. We'll keep a dataset of 15k training images and 3k validation images, and a 3k test set. First we reshape and save the training set and its labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3cbd9b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_train = X_train[0:18000,:,:].reshape(18000,784)\n",
    "ys_train = y_train[0:18000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00b35bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"MNIST_Small_Training_FlatImg.npy\", Xs_train)\n",
    "np.save(\"MNIST_Small_Training_Labels.npy\", ys_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6163b9c",
   "metadata": {},
   "source": [
    "Next we do the same with the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7ff39538",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_test = X_test[0:3000,:,:].reshape(3000,784)\n",
    "ys_test = y_test[0:3000]\n",
    "np.save(\"MNIST_Small_Test_FlatImg.npy\", Xs_test)\n",
    "np.save(\"MNIST_Small_Test_Labels.npy\", ys_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac04cbd",
   "metadata": {},
   "source": [
    "Clear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6a611949",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, Xs_train, y_train, ys_train, X_test, Xs_test, y_test, ys_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c58794",
   "metadata": {},
   "source": [
    "### MNIST reduced\n",
    "\n",
    "(Re)Load smaller datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43e21b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(file = \"MNIST_Small_Training_FlatImg.npy\")\n",
    "y_train = np.load(file = \"MNIST_Small_Training_Labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31d3b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(file = \"MNIST_Small_Test_FlatImg.npy\")\n",
    "y_test = np.load(file = \"MNIST_Small_Test_Labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92337cea-3b7f-4b52-94fe-6b4c3e3c6c47",
   "metadata": {},
   "source": [
    "## 2) Keras ANN\n",
    "### 22/07/05\n",
    "\n",
    "For comparison purposes. More discussion and motivation in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "394081f1-2d0b-4449-8e59-31431b127446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22da19ab-3aae-433a-9568-6ccf7a19f3e5",
   "metadata": {},
   "source": [
    "Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7382277-3eec-42fa-a437-6b4b8bcf4c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "X_train = np.load(file = \"MNIST_Small_Training_FlatImg.npy\")\n",
    "y_train = np.load(file = \"MNIST_Small_Training_Labels.npy\")\n",
    "# Testing\n",
    "X_test = np.load(file = \"MNIST_Small_Test_FlatImg.npy\")\n",
    "y_test = np.load(file = \"MNIST_Small_Test_Labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "723e734b-a92f-4789-9c8a-90543214ea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattened images:\n",
    "x_train = X_train[0:15000]/255\n",
    "x_val = X_train[15000:]/255\n",
    "x_test = X_test/255\n",
    "\n",
    "# One-hot labels:\n",
    "y_cat_train = to_categorical(y_train[:15000], num_classes = 10)\n",
    "y_cat_val = to_categorical(y_train[15000:], num_classes = 10)\n",
    "y_cat_test = to_categorical(y_test, num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a1d972-74a2-457b-90f3-1d54910f2889",
   "metadata": {},
   "source": [
    "Now we make the model. Previously, as a baseline we'll use:\n",
    "* Input layer of input shape = 784;\n",
    "* Layer 1 with 128 units and ReLU activation;\n",
    "* Layer 2 with 64 units and ReLU activation;\n",
    "* Output with 10 units and \"softmax\" activation;\n",
    "* Adam optimizer with learning rate = 0.001;\n",
    "* Cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30306ae9-da11-4fff-b85d-4c4123e902f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_dim = 784\n",
    "layer_1_n_units = 128\n",
    "layer_2_n_units = 64\n",
    "output_dim = 10\n",
    "learn_rate = 0.001\n",
    "\n",
    "# Network\n",
    "keras_ann = Sequential()\n",
    "\n",
    "keras_ann.add(keras.Input(shape = (input_dim,))) # Necessary?\n",
    "keras_ann.add(Dense(units = layer_1_n_units, activation = \"relu\"))\n",
    "keras_ann.add(Dense(units = layer_2_n_units, activation = \"relu\"))\n",
    "keras_ann.add(Dense(units = output_dim, activation = \"softmax\"))\n",
    "\n",
    "keras_ann.compile(optimizer= keras.optimizers.Adam(learning_rate=learn_rate), \\\n",
    "                  loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86d8c79-7e95-4a84-b77e-3b9b8d5aa7de",
   "metadata": {},
   "source": [
    "Now we train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "849f4621-2382-4042-a1e7-5fdb297e8aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.5974 - accuracy: 0.8302 - val_loss: 0.3220 - val_accuracy: 0.9010\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.2367 - accuracy: 0.9327 - val_loss: 0.2378 - val_accuracy: 0.9290\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.1690 - accuracy: 0.9508 - val_loss: 0.1934 - val_accuracy: 0.9393\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.1255 - accuracy: 0.9634 - val_loss: 0.1702 - val_accuracy: 0.9470\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0961 - accuracy: 0.9713 - val_loss: 0.1612 - val_accuracy: 0.9527\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.0752 - accuracy: 0.9788 - val_loss: 0.1608 - val_accuracy: 0.9537\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0632 - accuracy: 0.9830 - val_loss: 0.1495 - val_accuracy: 0.9547\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0475 - accuracy: 0.9873 - val_loss: 0.1574 - val_accuracy: 0.9543\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0360 - accuracy: 0.9909 - val_loss: 0.1394 - val_accuracy: 0.9583\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0292 - accuracy: 0.9935 - val_loss: 0.1563 - val_accuracy: 0.9537\n",
      "Training of keras_ann done. Time elapsed: 0:00:07.066415.\n"
     ]
    }
   ],
   "source": [
    "train_begin_time = datetime.now()\n",
    "keras_ann.fit( x = x_train,\n",
    "              y = y_cat_train,\n",
    "              batch_size = 100,\n",
    "              epochs = 10,\n",
    "              verbose = 1,\n",
    "              validation_data = (x_val, y_cat_val)\n",
    "              )\n",
    "print(f\"Training of keras_ann done. Time elapsed: {datetime.now()-train_begin_time}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2563a5f0-ca3c-4d89-af57-0623265fd8da",
   "metadata": {},
   "source": [
    "Plot some learning curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b3d055d-9be9-453c-90ec-7e2f290df761",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hist = pd.DataFrame(keras_ann.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d80918ea-380e-4393-b603-24a17c1ca53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['loss', 'accuracy', 'val_loss', 'val_accuracy'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hist.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e3a4e80-1b62-49bf-ba92-098f086906fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f0780ddbb0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_hist[[\"loss\", \"val_loss\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a49988e-a673-4ddf-a2d7-909158f041ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f078822610>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_hist[[\"accuracy\", \"val_accuracy\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64296d0-9587-48b5-a91e-e474f26756b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ecb9f9-2c1f-422d-b97c-0b1d1a923132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28272362",
   "metadata": {},
   "source": [
    "## 3) Keras CNN\n",
    "\n",
    "Before constructing our neural net from scratch using TF1 graphs, we give a quicker implementation of the desired neural net. \n",
    "\n",
    "**Reference:** Pierian Data's \"Tensorflow 2/Keras Deep Learning Bootcamp\", section on CNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef85dd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# This will kill the warnings with pink background\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e797ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8f3b6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef68223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff80098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed581e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For one-hot encoding of labels\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1564a61",
   "metadata": {},
   "source": [
    "Start with the following simple model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "138f7ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init.\n",
    "n_pxs = 28\n",
    "batch_size = 100\n",
    "\n",
    "# Instantiate model\n",
    "cnn_model = Sequential()\n",
    "\n",
    "## Add layers, input->conv->maxpool->flatten->dense->dense\n",
    "\n",
    "# Input layer, conv\n",
    "cnn_model.add(Conv2D(filters= 32, kernel_size= (4,4),\\\n",
    "                     activation = \"relu\", input_shape=(n_pxs,n_pxs,1)))\n",
    "# 2nd layer, maxpool\n",
    "cnn_model.add(MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "# 3rd layer, flatten\n",
    "cnn_model.add(Flatten())\n",
    "# 4th layer, dense\n",
    "cnn_model.add(Dense(units = 128, activation = \"relu\"))\n",
    "# Out layer, dense\n",
    "cnn_model.add(Dense(units = 10, activation = \"softmax\"))\n",
    "\n",
    "# Compile model\n",
    "cnn_model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54a74ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 25, 25, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 591,786\n",
      "Trainable params: 591,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56d490a",
   "metadata": {},
   "source": [
    "Need to pre-process the data after loading it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae442c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "X_train = np.load(file = \"MNIST_Small_Training_FlatImg.npy\")\n",
    "y_train = np.load(file = \"MNIST_Small_Training_Labels.npy\")\n",
    "# Testing\n",
    "X_test = np.load(file = \"MNIST_Small_Test_FlatImg.npy\")\n",
    "y_test = np.load(file = \"MNIST_Small_Test_Labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1ca0f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train[0:15000]/255\n",
    "x_train = x_train.reshape(15000, 28, 28, 1)\n",
    "x_val = X_train[15000:]/255\n",
    "x_val = x_val.reshape(3000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "508e6d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat = to_categorical(y_train[0:15000])\n",
    "y_val_cat = to_categorical(y_train[15000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269d5701",
   "metadata": {},
   "source": [
    "Train with validation set.\n",
    "**IMPORTANT:** Will not execute if eager execution isn't enabled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4523acc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "tf.enable_eager_execution must be called at program startup.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-650dd8b5c1e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_eager_execution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36menable_eager_execution\u001b[1;34m(config, device_policy, execution_mode)\u001b[0m\n\u001b[0;32m   5893\u001b[0m   \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Enabling eager execution\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5894\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_execution_mode\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEAGER_MODE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5895\u001b[1;33m     return enable_eager_execution_internal(\n\u001b[0m\u001b[0;32m   5896\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5897\u001b[0m         \u001b[0mdevice_policy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice_policy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36menable_eager_execution_internal\u001b[1;34m(config, device_policy, execution_mode, server_def)\u001b[0m\n\u001b[0;32m   5956\u001b[0m         _default_graph_stack._global_default_graph is not None)  # pylint: disable=protected-access\n\u001b[0;32m   5957\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgraph_mode_has_been_used\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5958\u001b[1;33m       raise ValueError(\n\u001b[0m\u001b[0;32m   5959\u001b[0m           \"tf.enable_eager_execution must be called at program startup.\")\n\u001b[0;32m   5960\u001b[0m   \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_execution_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEAGER_MODE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: tf.enable_eager_execution must be called at program startup."
     ]
    }
   ],
   "source": [
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2368ab91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 39s 25ms/step - loss: 0.6002 - accuracy: 0.8195 - val_loss: 0.1610 - val_accuracy: 0.9510\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.1151 - accuracy: 0.9653 - val_loss: 0.0967 - val_accuracy: 0.9713\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.0583 - accuracy: 0.9833 - val_loss: 0.0988 - val_accuracy: 0.9723\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.0347 - accuracy: 0.9910 - val_loss: 0.0824 - val_accuracy: 0.9720\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.0262 - accuracy: 0.9914 - val_loss: 0.0911 - val_accuracy: 0.9747\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.0172 - accuracy: 0.9953 - val_loss: 0.0768 - val_accuracy: 0.9783\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 0.0719 - val_accuracy: 0.9803\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.0890 - val_accuracy: 0.9750\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.0770 - val_accuracy: 0.9793\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.1066 - val_accuracy: 0.9703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x255110718e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(x_train, y_train_cat, epochs = 10, validation_data=(x_val, y_val_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386f9505",
   "metadata": {},
   "source": [
    "Save trained model for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66281c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.save(\"MNIST_Small_Trained_CNN.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce3eff0",
   "metadata": {},
   "source": [
    "Let's check if it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21cea164",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = X_test[10].reshape(28,28)\n",
    "img_2 = X_test[20].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ce2bb92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25bb89f4400>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be16d8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25bb8ad4a30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff005423",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cat = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0bf3f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_cat[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17339666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d92ba3d",
   "metadata": {},
   "source": [
    "Test the model:\n",
    "\n",
    "**First image:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "334af291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[20].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fb82fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2551d014cd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[20].reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b4df86",
   "metadata": {},
   "source": [
    "Before feeding the array to the model, recall:\n",
    "* First we need to reshape the (784,) image to (28,28,1), with the 1 at the end specifying no. of color channels.\n",
    "* Second, rescale the values to the interval [0,1], just like we did for the test set (i.e. divide by 255).\n",
    "* Thirdly, recall that current version of TF2 modifies input_shape from (28,28,1) to (None, 28,28,1), so reshape again again accordingly (e.g. using np.array([input_image]))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de8b7ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_1 = (X_test[20]/255).reshape(28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b456ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abe67e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4919124e-07, 1.0005291e-06, 1.2346462e-08, 2.5778587e-04,\n",
       "        4.1933020e-04, 9.2843635e-09, 9.0480592e-12, 5.4479414e-04,\n",
       "        7.8786127e-07, 9.9877602e-01]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.predict(np.array([test_img_1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2f61f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_1_pred = np.argmax(cnn_model.predict(np.array([test_img_1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e84b75fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img_1_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88de4fec",
   "metadata": {},
   "source": [
    "**Second image:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ece1f4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2551964e370>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[500].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8397007",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_2 = np.array([(X_test[500]/255).reshape(28,28,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa670139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a4d6c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "test_img_2_pred = np.argmax(cnn_model.predict(test_img_2))\n",
    "print(test_img_2_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea979f6",
   "metadata": {},
   "source": [
    "## 3) Classification in TF1 with ANN\n",
    "\n",
    "In this part we will classify the reduced MNIST dataset with a fully connected ANN.\n",
    "\n",
    "Let's start with the imports and data loading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ab3c0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# This will kill the warnings with pink background\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# To simplify the code\n",
    "import tensorflow.compat.v1 as tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e40ab592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\zaj20\\anaconda3\\envs\\DeepLearn\\Scripts\\matplotlib-script.py\", line 10, in <module>\n",
      "    sys.exit(plotting._matplotlib())\n",
      "AttributeError: module 'pandas.plotting' has no attribute '_matplotlib'\n"
     ]
    }
   ],
   "source": [
    "!matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c03aa6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "732abdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want this to work\n",
    "tf1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9322494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "##### MNIST- SMALL VERSION #####\n",
    "################################\n",
    "\n",
    "# Training\n",
    "X_train = np.load(file = \"MNIST_Small_Training_FlatImg.npy\")\n",
    "y_train = np.load(file = \"MNIST_Small_Training_Labels.npy\")\n",
    "\n",
    "# Testing\n",
    "X_test = np.load(file = \"MNIST_Small_Test_FlatImg.npy\")\n",
    "y_test = np.load(file = \"MNIST_Small_Test_Labels.npy\")\n",
    "\n",
    "# Pre-process\n",
    "x_train = X_train[0:15000]/255\n",
    "x_val = X_train[15000:]/255\n",
    "x_test = X_test/255\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_cat_train = to_categorical(y_train[0:15000])\n",
    "y_cat_val = to_categorical(y_train[15000:])\n",
    "y_cat_test = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7e13832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946acdc9",
   "metadata": {},
   "source": [
    "### a) An overview of the code\n",
    "\n",
    "The most time-consuming part of the process is building the computational graph of our neural net. The loose organization of the code is as follows:\n",
    "\n",
    "* **Part I: Implementation of the ANN**\n",
    "\n",
    "1) Create namescopes for the input data and labels $(X,Y)$. Here, we declare $X$ and $Y$ as ***placeholders***, and we specify their dtype along with their dimensions/shape. **Note:** The shape is of the form [None, input_dim] (and [None, num_classes]), where \"None\" is for the batch size that we don't necessarily know beforehand.\n",
    "\n",
    "2) Create namescopes for the network parameters (weights and biases) $(W^(l), b^(l))$ of the network. These are declared as ***Variables***, and must be initialized in the beginning of the training/testing sessions. Below, we will use TF's random number generators to initialize these parameters. Of course, we specify again the dtypes and the dimensions of these parameters. **Note:** For later visualization with TensorBoard, it's useful to add name arguments to the weights, and for computational efficiency, it's useful to gather the params in dictionaries.\n",
    "\n",
    "3) Create the namescope for the model, where the layers are also declared as ***Variables***. One possible implementation is:\n",
    "\n",
    "            with tf1.name_scope(\"Model\"):\n",
    "                layer_1 = tf1.nn.activation_1(tf1.add(tf1.matmul(X,weights[\"W_1\"]), biases[\"b_1\"], name = \"layer_1\")\n",
    "                layer_2 = tf1.nn.activation_2(tf1.add(tf1.matmul(layer_1,weights[\"W_2\"]), biases[\"b_2\"], name = \"layer_2\")\n",
    "                    ...\n",
    "                layer_out = tf1.nn.activation_out(tf1.add(tf1.matmul(layer_(n-1),weights[\"W_n\"]), biases[\"b_n\"], name = \"layer_n\")\n",
    "\n",
    "This is essentially what the Sequential.add() method of Keras does. In the classification example below, we'll just take a linear activation for the output layer, since the softmax will be called in the computation of the loss.\n",
    "\n",
    "4) Create the namescope for the loss. This is again a ***Variable***, and takes the output layer as an argument. For our classification problem:\n",
    "\n",
    "            with tf1.namescope(\"Loss\"):\n",
    "                loss = tf1.reduce_mean(tf1.nn.softmax_cross_entropy_with_logits(logits = layer_out, labels = Y))\n",
    "\n",
    "5) As with Sequential.compile(), we are done implementing the model once we specify the loss and the optimizer. The TF1 module for optimizers is tf1.train, and when instantiating the optimizer we ***specify*** that we seek to ***minimize the loss***:\n",
    "\n",
    "            optimizer = tf1.train.AdamOptimizer(learn_rate).minimize(loss)\n",
    "            \n",
    "\n",
    "* **Part II: The training session**\n",
    "\n",
    "Typically, the training session is as follows:\n",
    "\n",
    "            with tf1.Session() as training_sess:\n",
    "            \n",
    "                # Initialize the variables\n",
    "                training_sess.run(tf1.global_variables_initializer())\n",
    "                \n",
    "                for epoch = 1,...,n_epochs:\n",
    "                    \n",
    "                    # Init. epoch loss\n",
    "                    epoch_loss = 0\n",
    "                \n",
    "                    for batch = 1,..., n_batches:\n",
    "                        \n",
    "                        # Get batch and make feed dictionary\n",
    "                        feed_XY = {X: batch_x, Y: batch_y}\n",
    "                        \n",
    "                        # Run loss and optimizer - This executes Adam/SGD on one batch\n",
    "                        _, batch_loss = training_sess.run([optimizer, loss], feed_dict = feed_XY)\n",
    "                        epoch_loss += batch_loss\n",
    "                     \n",
    "                     # Compute average loss of epoch\n",
    "                     average_loss = epoch_loss/n_batches\n",
    "                     \n",
    "                     # Verbose\n",
    "                     print(epoch, average_loss, etc)\n",
    "                     \n",
    "Unlike Keras, we need to add instructions if we want to keep track of the loss, the accuracy, and to save the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864b45c5",
   "metadata": {},
   "source": [
    "### b) Dense NN construction\n",
    "\n",
    "The references we follow here are Ravichandiran's book, in particular:\n",
    "\n",
    "https://github.com/sudharsan13296/Deep-Reinforcement-Learning-With-Python/blob/master/08.%20A%20primer%20on%20TensorFlow/8.05%20Handwritten%20digits%20classification%20using%20TensorFlow.ipynb.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ee5ca57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\zaj20\\anaconda3\\envs\\DeepLearn\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Learning hyperparameters\n",
    "learn_rate = 0.001\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "#### Neuron numbers for each layer ####\n",
    "num_in = 784\n",
    "num_h1 = 128\n",
    "num_h2 = 64\n",
    "num_out = 10\n",
    "\n",
    "#### Namescopes for placeholders of input and output layers ####\n",
    "with tf1.name_scope(\"input\"):\n",
    "    X = tf1.placeholder(dtype = tf.float32, shape = [None, num_in])\n",
    "with tf.compat.v1.name_scope(\"output\"):\n",
    "    Y = tf1.placeholder(dtype = tf.float32, shape = [None, num_out])\n",
    "    \n",
    "#### Namescopes for layer weights and biases ####\n",
    "## This will be used as feed_dict later\n",
    "## Using the TF1 truncated normal with\n",
    "with tf1.name_scope(\"weights\"):\n",
    "    weights = {\"w1\":tf.Variable(tf1.truncated_normal(shape = (num_in, num_h1), stddev=0.1), name=\"weight_1\"),\n",
    "               \"w2\":tf.Variable(tf1.truncated_normal(shape = (num_h1, num_h2), stddev=0.1), name=\"weight_2\"),\n",
    "               \"w_out\":tf.Variable(tf1.truncated_normal(shape = (num_h2, num_out), stddev=0.1), name=\"weight_3\")\n",
    "              }\n",
    "    \n",
    "with tf.compat.v1.name_scope(\"biases\"):\n",
    "    biases = {\"b1\":tf.Variable(tf.constant(0.1, shape = [num_h1]), name=\"bias_1\"),\n",
    "              \"b2\":tf.Variable(tf.constant(0.1, shape = [num_h2]), name=\"bias_2\"),\n",
    "              \"b_out\":tf.Variable(tf.constant(0.1, shape = [num_out]), name=\"bias_3\")\n",
    "              } # Does this last line even make sense?\n",
    "    \n",
    "#### Namescope for forward propagation ####\n",
    "## The next block of code replaces Sequantial.add()\n",
    "## The layers are built by specifying what goes into each activation\n",
    "## Makes sense, but pretty cumbersome. Also explains why weights are transposed in Keras.\n",
    "with tf1.name_scope(\"Model\"):\n",
    "    with tf1.name_scope(\"layer1\"):\n",
    "        layer_1 = tf1.nn.relu(tf.add(tf.matmul(X,weights[\"w1\"]), biases[\"b1\"]) )\n",
    "    with tf1.name_scope(\"layer2\"):        \n",
    "        layer_2 = tf1.nn.relu(tf.add(tf.matmul(layer_1,weights[\"w2\"]), biases[\"b2\"]) )\n",
    "    with tf1.name_scope(\"output_layer\"):    \n",
    "        #layer_out = tf1.nn.softmax(tf.add(tf.matmul(layer_2,weights[\"w_out\"]), biases[\"b_out\"]) ) # Activation should be softmax\n",
    "        layer_out = tf.add(tf.matmul(layer_2,weights[\"w_out\"]), biases[\"b_out\"]) \n",
    "        \n",
    "#### Loss function ####\n",
    "with tf1.name_scope(\"Loss\"):\n",
    "    loss = tf1.reduce_mean(tf1.nn.softmax_cross_entropy_with_logits(logits = layer_out, labels = Y)) # CLARIFY\n",
    "    #loss = tf1.reduce_mean(tf1.nn.cross(logits = layer_out, labels = Y))\n",
    "    # cross-entropy loss\n",
    "\n",
    "#### Optimizer ####\n",
    "optimizer = tf1.train.AdamOptimizer(learning_rate = learn_rate).minimize(loss) # CLARIFY\n",
    "\n",
    "#### Accuracy ####\n",
    "with tf1.name_scope(\"Accuracy\"):\n",
    "    predicted_label = tf1.argmax(tf1.nn.softmax(layer_out),axis = 1)\n",
    "    true_label = tf1.argmax(Y,axis = 1)\n",
    "    prediction_correct = tf1.equal(predicted_label, true_label)\n",
    "    accuracy = tf1.reduce_mean(tf1.cast(prediction_correct, tf.float32))\n",
    "    \n",
    "# For TensorBoard\n",
    "tf1.summary.scalar(\"Accuracy\", accuracy)\n",
    "tf1.summary.scalar(\"Loss\", loss)\n",
    "merge_summary = tf1.summary.merge_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "586a9c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1; Loss: 0.7225; Accuracy: 79.59%.\n",
      "Epoch: 2; Loss: 0.2870; Accuracy: 91.82%.\n",
      "Epoch: 3; Loss: 0.2116; Accuracy: 93.87%.\n",
      "Epoch: 4; Loss: 0.1640; Accuracy: 95.23%.\n",
      "Epoch: 5; Loss: 0.1303; Accuracy: 96.27%.\n",
      "Epoch: 6; Loss: 0.1044; Accuracy: 97.14%.\n",
      "Epoch: 7; Loss: 0.0839; Accuracy: 97.80%.\n",
      "Epoch: 8; Loss: 0.0673; Accuracy: 98.34%.\n",
      "Epoch: 9; Loss: 0.0548; Accuracy: 98.71%.\n",
      "Epoch: 10; Loss: 0.0446; Accuracy: 99.02%.\n",
      "Training finished. Total time: 0:00:03.560165\n",
      "INFO:tensorflow:saved-models\\MNIST_ANN_Weights.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1300\n",
      "INFO:tensorflow:saved-models\\MNIST_ANN_Weights.ckpt.index\n",
      "INFO:tensorflow:1300\n",
      "INFO:tensorflow:saved-models\\MNIST_ANN_Weights.ckpt.meta\n",
      "INFO:tensorflow:1400\n",
      "Trained ANN saved at saved-models/MNIST_ANN_Weights.ckpt as MNIST_ANN_Weights.ckpt\n",
      "Accuracy on validation set: 94.90%\n"
     ]
    }
   ],
   "source": [
    "# Training session\n",
    "\n",
    "init = tf1.global_variables_initializer()\n",
    "\n",
    "n_batches = np.int(len(x_train)/batch_size)\n",
    "\n",
    "# Inst. saver object\n",
    "training_saver = tf1.train.Saver()\n",
    "model_fname = \"MNIST_ANN_Weights.ckpt\"\n",
    "\n",
    "with tf1.Session() as denseNN_sess:\n",
    "    \n",
    "    # Init. global variables\n",
    "    denseNN_sess.run(init)\n",
    "    \n",
    "    # Inst. summary writer\n",
    "    summary_writer = tf1.summary.FileWriter(\"./graphs\", graph = tf1.get_default_graph())\n",
    "    \n",
    "    # Init. timer\n",
    "    time_begin_training = datetime.now()\n",
    "    \n",
    "    # Loop over training epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        epoch_loss = 0.0\n",
    "        epoch_accuracy = 0.0\n",
    "        \n",
    "        # Loop over batches\n",
    "        for i_batch in range(n_batches):\n",
    "            \n",
    "            # Batches\n",
    "            batch_x = x_train[i_batch*batch_size:(i_batch+1)*batch_size]\n",
    "            batch_y = y_cat_train[i_batch*batch_size:(i_batch+1)*batch_size]\n",
    "            \n",
    "            # Feed dictionary\n",
    "            batch_feed = {X:batch_x, Y:batch_y}\n",
    "            \n",
    "            # Run SGD\n",
    "            ## I don't get this instruction\n",
    "            #batch_loss, batch_accuracy, summary = denseNN_sess.run([loss, accuracy, merge_summary],\\\n",
    "            #                                                       feed_dict = batch_feed)\n",
    "            _, batch_loss, batch_accuracy = denseNN_sess.run([optimizer, loss, accuracy], feed_dict = batch_feed)\n",
    "            epoch_loss += batch_loss\n",
    "            epoch_accuracy += batch_accuracy\n",
    "            \n",
    "        \n",
    "        average_loss = epoch_loss/n_batches\n",
    "        average_accuracy = epoch_accuracy/n_batches\n",
    "        \n",
    "        # Add to summary\n",
    "        #summary_writer.add_summary(summary, epoch)\n",
    "        #print(f\"Epoch: {epoch+1}; Loss: {average_loss}; Accuracy: {batch_accuracy}.\")\n",
    "        print(f\"Epoch: {epoch+1}; Loss: {average_loss:5.4f}; Accuracy: {average_accuracy*100:3.2f}%.\")\n",
    "        \n",
    "    # Training tot. time\n",
    "    tot_training_time = datetime.now() - time_begin_training\n",
    "    print(f\"Training finished. Total time: {tot_training_time}\")\n",
    "    \n",
    "    # Save trained model\n",
    "    trained_model_file = training_saver.save(sess = denseNN_sess,save_path = 'saved-models/'+model_fname)\n",
    "    print(f\"Trained ANN saved at {trained_model_file} as {model_fname}\")\n",
    "    \n",
    "    # Compute accuracy on validation set\n",
    "    validation_feed = {X:x_val, Y:y_cat_val}\n",
    "    accuracy_val_set = denseNN_sess.run(accuracy, feed_dict = validation_feed)\n",
    "    \n",
    "    '''\n",
    "    predictions_check = tf1.equal(tf1.argmax(layer_5_out,1),tf1.argmax(Y,1)) # CLARIFY\n",
    "    accuracy_val_set = tf1.reduce_mean(tf1.cast(predictions_check, tf.float32)) # CLARIFY\n",
    "    validation_feed = {X:x_val, Y:y_cat_val}\n",
    "    '''\n",
    "    print(f\"Accuracy on validation set: {accuracy_val_set*100:3.2f}%\") # CLARIFY\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea1603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "del denseNN_sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edb019e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328bc3c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5b4f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f177917c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_cat_test[1236] = [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_id = np.random.randint(0,3000)\n",
    "\n",
    "print(f\"y_cat_test[{img_id}] = {y_cat_test[img_id]}\")\n",
    "\n",
    "plt.imshow(x_test[img_id].reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215a9076",
   "metadata": {},
   "source": [
    "Now we test our model on the test set. \n",
    "\n",
    "**Comment:** The main issue here is how you initialize the variables in your session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab468e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_sess_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4bddc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from saved-models/MNIST_ANN_Weights.ckpt\n",
      "Accuracy on test set: 94.57%\n"
     ]
    }
   ],
   "source": [
    "saver = tf1.train.Saver()\n",
    "\n",
    "with tf1.Session() as test_sess_1:\n",
    "    \n",
    "    # Load saved model\n",
    "    saver.restore(test_sess_1, \"saved-models/MNIST_ANN_Weights.ckpt\")\n",
    "    \n",
    "    # Compute and print accuracy\n",
    "    test_feed = {X:x_test, Y: y_cat_test}\n",
    "    accuracy_test_set = test_sess_1.run(accuracy, feed_dict = test_feed)\n",
    "    print(f\"Accuracy on test set: {accuracy_test_set*100:3.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e52217a",
   "metadata": {},
   "source": [
    "_____________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3331a2cc",
   "metadata": {},
   "source": [
    "### 3.b - CNN with TF1.x\n",
    "\n",
    "In this part, I'm re-implementing the previous Keras CNN in TF1 format. My references for this part are the following notebooks:\n",
    "\n",
    "* https://github.com/sudharsan13296/Deep-Reinforcement-Learning-With-Python/blob/master/08.%20A%20primer%20on%20TensorFlow/8.05%20Handwritten%20digits%20classification%20using%20TensorFlow.ipynb\n",
    "\n",
    "* https://github.com/armando-fandango/Mastering-TensorFlow/blob/master/Chapter09/ch-09a_CNN_MNIST_TF_and_Keras.ipynb\n",
    "\n",
    "* https://github.com/PacktPublishing/TensorFlow-1x-Deep-Learning-Cookbook/blob/master/Chapter04/CNN_MINST.ipynb\n",
    "\n",
    "As usual, we start with the relevant imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fba03d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# This will kill the warnings with pink background\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# To simplify the code\n",
    "import tensorflow.compat.v1 as tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a8b7235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\Scripts\\matplotlib-script.py\", line 10, in <module>\n",
      "    sys.exit(plotting._matplotlib())\n",
      "AttributeError: module 'pandas.plotting' has no attribute '_matplotlib'\n"
     ]
    }
   ],
   "source": [
    "!matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e98fa395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the seed\n",
    "tf1.set_random_seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b1bafaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df46b016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want this to work\n",
    "tf1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac70d82",
   "metadata": {},
   "source": [
    "Next, we load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98141938",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "##### MNIST- SMALL VERSION #####\n",
    "################################\n",
    "\n",
    "# Training\n",
    "X_train = np.load(file = \"MNIST_Small_Training_FlatImg.npy\")\n",
    "y_train = np.load(file = \"MNIST_Small_Training_Labels.npy\")\n",
    "\n",
    "# Testing\n",
    "X_test = np.load(file = \"MNIST_Small_Test_FlatImg.npy\")\n",
    "y_test = np.load(file = \"MNIST_Small_Test_Labels.npy\")\n",
    "\n",
    "# Pre-process\n",
    "x_train = X_train[0:15000]/255\n",
    "x_val = X_train[15000:]/255\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_cat_train = to_categorical(y_train[0:15000])\n",
    "y_cat_val = to_categorical(y_train[15000:])\n",
    "y_cat_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1b3e2e",
   "metadata": {},
   "source": [
    "The desired architecture is as follows:\n",
    "\n",
    "            \n",
    "            cnn_model = Sequential()\n",
    "\n",
    "            ## Layers:\n",
    "            cnn_model.add(Conv2D(filters= 32, kernel_size= (4,4),\\\n",
    "                                 activation = \"relu\", input_shape=(n_pxs,n_pxs,1)))\n",
    "            cnn_model.add(MaxPool2D(pool_size = (2,2)))\n",
    "            cnn_model.add(Flatten())\n",
    "            cnn_model.add(Dense(units = 128, activation = \"relu\"))\n",
    "            cnn_model.add(Dense(units = 10, activation = \"softmax\"))\n",
    "\n",
    "            # Compile model\n",
    "            cnn_model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "* A 2d convolutional input layer, of input size (28,28,1) and ReLU activation.\n",
    "* A maxpooling layer with ReLU activation, (2,2) pool size.\n",
    "* A flattening layer (no activation).\n",
    "* A dense layer with ReLU activation and 128 neurons.\n",
    "* An output layer with 10 units and softmax activation.\n",
    "\n",
    "**Comments on the CNN:**\n",
    "\n",
    "* I don't understand why last layer doesn't have a softmax activation. \n",
    "\n",
    "* The softmax is part of the loss used here, which is **tf1.nn.softmax_cross_entropy_with_logits**.\n",
    "\n",
    "* Important question: How do you make the design of a neural net in TF1.x modular? To clarify: In Keras, you create one Sequential() object to which you add the layers. For TF, it is unclear how you organize your code, given that you are building a graph. Different authors seem to have different approaches, and I haven't found one that combines  namescopes, new classes, and helper functions.\n",
    "\n",
    "* Partial answer. Following notebook seems to follow the practice of building the NNs using helper functions: \n",
    "\n",
    "  https://github.com/PacktPublishing/TensorFlow-1x-Deep-Learning-Cookbook/blob/master/Chapter04/CNN_MINST.ipynb\n",
    "\n",
    "  This code is much better organized, but doesn't answer all my questions.\n",
    "\n",
    "* Helper functions are used to avoid the long calls to methods/classes in TF1 (I think this is what people call wrappers).\n",
    "\n",
    "The next cell records the hyperparameters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83adf8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "##### Network hyperparameters #####\n",
    "###################################\n",
    "\n",
    "# Input/Final Output\n",
    "n_classes = 10\n",
    "n_width = 28\n",
    "n_height = 28\n",
    "n_channels = 1\n",
    "input_dim = n_height*n_width*n_channels\n",
    "\n",
    "# Conv. layer\n",
    "conv_ker_ht = 4\n",
    "conv_ker_wd = 4\n",
    "conv_n_filters = 32\n",
    "'''\n",
    "  General fomula (Calin Ex.16.9.11): \n",
    "  For input of shape (h_in, w_in), kernel of shape (k_ver, k_hor),\n",
    "  strides (s_ver, s_hor), and padding p, the output shape (h_out, w_out)\n",
    "  is given by:\n",
    "    h_out = (h_in-k_ver+2p)/s_ver +1; w_out = (w_in-k_hor+2p)/s_hor +1.\n",
    "  Note additional constraint that stride has to divide (dim_in-filter_dim+2*padding)\n",
    "\n",
    "'''\n",
    "conv_out_ht = n_height-conv_ker_ht +1\n",
    "conv_out_wd = n_width-conv_ker_wd +1\n",
    "\n",
    "# MaxPool layer\n",
    "pool_ver = 2 \n",
    "pool_hor = 2\n",
    "\n",
    "# Flatten layer\n",
    "\n",
    "# Fully conn. 1 (post flattening)\n",
    "fc1_dim_in = np.int(conv_out_ht/pool_ver)*\\\n",
    "             np.int(conv_out_wd/pool_hor)*\\\n",
    "             conv_n_filters\n",
    "fc1_dim_out = 128\n",
    "\n",
    "# Training\n",
    "learn_rate = 0.01\n",
    "n_epochs = 20\n",
    "batch_size = 100\n",
    "n_batches = np.int(x_train.shape[0]/batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00807bc",
   "metadata": {},
   "source": [
    "Here is our model now. As we'll see in TensorBoard, using namescopes groups all the subgraphs into nodes of the computational graph. I prefer this to Fandago's implementation since it gives a much cleaner graph in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08560b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf1.reset_default_graph()\n",
    "\n",
    "# Placeholders for input images and labels\n",
    "## x are the flattened images, y the labels\n",
    "with tf1.name_scope(\"Input\"):\n",
    "    x = tf1.placeholder(dtype = tf.float32, name = \"x\", shape = (None, input_dim))\n",
    "    x_ = tf1.reshape(x, shape = (-1,n_height,n_width,n_channels)) # Reshape input to TF1 image format\n",
    "with tf1.name_scope(\"Output\"):\n",
    "    y = tf1.placeholder(dtype = tf.float32, name = \"y\", shape = (None, n_classes))\n",
    "\n",
    "# Weights\n",
    "with tf1.name_scope(\"Weights\"):\n",
    "    weights = {\"W1\":tf1.Variable(tf1.random_normal(shape=[conv_ker_ht, conv_ker_wd, n_channels, conv_n_filters],\\\n",
    "                                                   stddev=0.1), name = \"W_1\"),\\\n",
    "             \"W4\":tf1.Variable(tf1.random_normal(shape=[fc1_dim_in, fc1_dim_out]), name = \"W_4\") ,\\\n",
    "             \"W5\":tf1.Variable(tf1.random_normal(shape = [fc1_dim_out, n_classes]), name = \"W_5\") }\n",
    "# Biases\n",
    "with tf1.name_scope(\"Biases\"):\n",
    "    biases = {\"b1\":tf1.Variable(tf1.random_normal([conv_n_filters]), name = \"b_1\"),\\\n",
    "            \"b4\":tf1.Variable(tf1.random_normal(shape=[fc1_dim_out]), name = \"b_4\"),\\\n",
    "            \"b5\":tf1.Variable(tf1.random_normal(shape = [n_classes]), name = \"b_5\")}\n",
    "\n",
    "# Model\n",
    "with tf1.name_scope(\"Model\"):\n",
    "    \n",
    "    with tf1.name_scope(\"Layer_1\"):\n",
    "        layer_1 = tf1.nn.relu(tf.add(tf1.nn.conv2d(x_, weights[\"W1\"], strides = [1,1,1,1], padding=\"VALID\" ),biases[\"b1\"]))\n",
    "    \n",
    "    with tf1.name_scope(\"Layer_2\"):\n",
    "        layer_2 = tf1.nn.max_pool2d(layer_1, ksize = [1,pool_ver,pool_hor,1], strides = [1,pool_ver,pool_hor,1],\\\n",
    "                                    padding= \"VALID\")\n",
    "\n",
    "    with tf1.name_scope(\"Layer_3\"):\n",
    "        layer_3 = tf1.reshape(layer_2, shape = (-1,fc1_dim_in))\n",
    "\n",
    "    with tf1.name_scope(\"Layer_4\"):\n",
    "        layer_4 = tf1.nn.relu(tf1.add(tf.matmul(layer_3,weights[\"W4\"]), biases[\"b4\"]))\n",
    "\n",
    "    with tf1.name_scope(\"Layer_5_out\"):\n",
    "        layer_5_out = tf1.add(tf1.matmul(layer_4,weights[\"W5\"]), biases[\"b5\"])\n",
    "\n",
    "# Loss function\n",
    "with tf1.name_scope(\"Loss\"):\n",
    "    loss = tf1.reduce_mean(tf1.nn.softmax_cross_entropy_with_logits(logits=layer_5_out, labels = y))\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf1.train.AdamOptimizer(learning_rate = learn_rate).minimize(loss) # CLARIFY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afd890e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f1f714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e137508",
   "metadata": {},
   "source": [
    "**Comments on the training session:** This is where we *run* the computational graph.\n",
    "1) I'm following \"Train and evaluate\" cell at: \n",
    "\n",
    "https://github.com/armando-fandango/Mastering-TensorFlow/blob/master/Chapter09/ch-09a_CNN_MNIST_TF_and_Keras.ipynb\n",
    "\n",
    "See documentation of Session.run() at https://www.tensorflow.org/api_docs/python/tf/compat/v1/Session#run. This is the main call of the algorithm below obviously.\n",
    "\n",
    "2) Regarding saving and loading a trained model, Fandago has the following notebook:\n",
    "\n",
    "https://github.com/armando-fandango/Mastering-TensorFlow/blob/master/Chapter11/ch-11a_Saving_and_Restoring_TF_Models.ipynb\n",
    "\n",
    "Highlights:\n",
    "\n",
    "* To **save all variables in a graph**, one first makes a saver object:\n",
    "\n",
    "      saver = tf.compat.v1.train.Saver()\n",
    "\n",
    "  then uses a line of the form:\n",
    "\n",
    "      saved_model_file = saver.save(tfs,'saved-models/full-graph-save-example.ckpt')\n",
    "\n",
    "  in the session.\n",
    "\n",
    "* To **restore all variables** in a graph, after instantiating a saver object, one uses the following in a session:\n",
    "\n",
    "      saved_model_file = saver.restore(tfs,'saved-models/full-graph-save-example.ckpt')\n",
    "\n",
    "  The default graph should re-initialized between sessions, and to execute the last command, we do not use the global variables initializer.\n",
    "\n",
    "* In the link above, Fandago also shows how to save selected variables in a graph.\n",
    "\n",
    "\n",
    "A training TF session for our model is as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b52b36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-27 20:35:56.737624\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0e3d5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = np.int(x_train.shape[0]/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17aafc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss = 42.795692292849225\n",
      "Epoch: 2, loss = 4.174912639458975\n",
      "Epoch: 3, loss = 2.6393320559461912\n",
      "Epoch: 4, loss = 2.247205887834231\n",
      "Epoch: 5, loss = 1.6573192673176527\n",
      "Epoch: 6, loss = 1.553202390919129\n",
      "Epoch: 7, loss = 1.4920133795837562\n",
      "Epoch: 8, loss = 1.2301429014752892\n",
      "Epoch: 9, loss = 0.9753422121241844\n",
      "Epoch: 10, loss = 0.750030925233638\n",
      "Epoch: 11, loss = 0.6569595837518378\n",
      "Epoch: 12, loss = 0.5218218749819667\n",
      "Epoch: 13, loss = 0.4599154648793861\n",
      "Epoch: 14, loss = 0.4828951061667115\n",
      "Epoch: 15, loss = 0.3956152737833533\n",
      "Epoch: 16, loss = 0.31581682828809493\n",
      "Epoch: 17, loss = 0.32067511161665097\n",
      "Epoch: 18, loss = 0.27669874111861514\n",
      "Epoch: 19, loss = 0.27584116245503615\n",
      "Epoch: 20, loss = 0.2667518464675436\n",
      "End of training of CNN-v3. Time elapsed: 0:01:38.160211.\n",
      "Trained CNN saved at saved-models/CNN-v3_Weights.ckpt\n",
      "Accuracy: 0.937666654586792\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "#### Training Session ####\n",
    "##########################\n",
    "\n",
    "# Reset\n",
    "#tf1.reset_default_graph()\n",
    "\n",
    "# Inst. saver object\n",
    "training_saver = tf1.train.Saver()\n",
    "model_fname = \"CNN-v3_Weights.ckpt\"\n",
    "\n",
    "# Start new session\n",
    "with tf1.Session() as sess_cnn_v3:\n",
    "     \n",
    "    # Initialize global variables\n",
    "    tf1.global_variables_initializer().run()\n",
    "    \n",
    "    # Init. timer\n",
    "    train_begin_time = datetime.now()\n",
    "    \n",
    "    # Loop over epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        # Init. tot. loss\n",
    "        total_loss = 0.0\n",
    "\n",
    "        # Loop over batches\n",
    "        for i_batch in range(n_batches):\n",
    "            \n",
    "            # Get batch\n",
    "            batch_x = x_train[i_batch*batch_size:(i_batch+1)*batch_size]\n",
    "            batch_y = y_cat_train[i_batch*batch_size:(i_batch+1)*batch_size]\n",
    "            \n",
    "            # Make feed dictionary\n",
    "            batch_feed = {x:batch_x, y:batch_y}\n",
    "            \n",
    "            # Run CNN\n",
    "            ## Note: \n",
    "            batch_loss, info = sess_cnn_v3.run([loss, optimizer], feed_dict = batch_feed)\n",
    "            total_loss += batch_loss\n",
    "        \n",
    "        #Average loss\n",
    "        avg_loss = total_loss/n_batches\n",
    "        print(f\"Epoch: {epoch+1}, loss = {avg_loss}\")\n",
    "        \n",
    "    \n",
    "    # End of training\n",
    "    train_tot_time = datetime.now()- train_begin_time\n",
    "    print(f\"End of training of CNN-v3. Time elapsed: {train_tot_time}.\")\n",
    "    \n",
    "    # Save trained model\n",
    "    trained_model_file = training_saver.save(sess = sess_cnn_v3,save_path = 'saved-models/'+model_fname)\n",
    "    print(f\"Trained CNN saved at {trained_model_file}\")\n",
    "    \n",
    "    # Save graph\n",
    "    writer = tf1.summary.FileWriter(logdir = \"./graphs\", graph=sess_cnn_v3.graph)\n",
    "    \n",
    "    \n",
    "    # Compute accuracy on validation set\n",
    "    ### Following\n",
    "    predictions_check = tf1.equal(tf1.argmax(layer_5_out,1),tf1.argmax(y,1)) # CLARIFY\n",
    "    accuracy = tf1.reduce_mean(tf1.cast(predictions_check, tf.float32)) # CLARIFY\n",
    "    validation_feed = {x:x_val, y:y_cat_val}\n",
    "    print(f\"Accuracy: {accuracy.eval(feed_dict= validation_feed)}\") # CLARIFY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acc3b22",
   "metadata": {},
   "source": [
    "**Comment:** In Colab, the training time for this model takes around 2min 30 for roughly the same final accuracy.\n",
    "\n",
    "**TensorBoard:** We can look at our computational graph now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d81a57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 3400), started 0:21:36 ago. (Use '!kill 3400' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4327cbab0030814b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4327cbab0030814b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tensorboard\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "%load_ext tensorboard\n",
    "\n",
    "'''\n",
    "  To call this use\n",
    "  %tensorboard --logdir ./graphs\n",
    "  IMPORTANT: Ensure that you called tf1.summary.FileWriter(logdir = \"./graphs\", graph=session_name.graph)\n",
    "'''\n",
    "%tensorboard --logdir ./graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2636837f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
