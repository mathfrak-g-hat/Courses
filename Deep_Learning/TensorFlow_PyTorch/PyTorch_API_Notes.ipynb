{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "289b6693",
   "metadata": {},
   "source": [
    "# **Introduction to PyTorch**\n",
    "### 2022/06/29, AJ Zerouali\n",
    "### Updated: 2022/07/16\n",
    "\n",
    "## 1) Introduction\n",
    "\n",
    "The purpose of this notebook is to gain a basic understanding of PyTorch. I'm following some sections of Pierian Data's course on medical imaging with PyTorch, which I'll abbreviate as PDMIPT from now onwards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06352536",
   "metadata": {},
   "source": [
    "## 2) From NumPy arrays to PyTorch Tensors.\n",
    "\n",
    "**References:** I'm loosely following:\n",
    "- Section 4 of the PDMIPT course.\n",
    "- Chapter 3 of Lapan's \"Deep reinforcement learning with PyTorch\".\n",
    "\n",
    "As usual, we start with the imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f54a9d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "231be15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08462beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main import of this notebook\n",
    "import torch as T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb23fe8",
   "metadata": {},
   "source": [
    "#### Topics to cover\n",
    "\n",
    "* PyTorch tensors.\n",
    "* Automatic differentiation.\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266c35f7",
   "metadata": {},
   "source": [
    "#### Tensor operations:\n",
    "\n",
    "The following is from the \"Tensor Operations\" notebook of PDMIPT:\n",
    "\n",
    "<table style=\"display: inline-block\">\n",
    "<caption style=\"text-align: center\"><strong>Arithmetic</strong></caption>\n",
    "<tr><th>OPERATION</th><th>FUNCTION</th><th>DESCRIPTION</th></tr>\n",
    "<tr><td>a + b</td><td>a.add(b)</td><td>element wise addition</td></tr>\n",
    "<tr><td>a - b</td><td>a.sub(b)</td><td>subtraction</td></tr>\n",
    "<tr><td>a * b</td><td>a.mul(b)</td><td>multiplication</td></tr>\n",
    "<tr><td>a / b</td><td>a.div(b)</td><td>division</td></tr>\n",
    "<tr><td>a % b</td><td>a.fmod(b)</td><td>modulo (remainder after division)</td></tr>\n",
    "<tr><td>a<sup>b</sup></td><td>a.pow(b)</td><td>power</td></tr>\n",
    "<tr><td>&nbsp;</td><td></td><td></td></tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "<table style=\"display: inline-block\">\n",
    "<caption style=\"text-align: center\"><strong>Monomial Operations</strong></caption>\n",
    "<tr><th>OPERATION</th><th>FUNCTION</th><th>DESCRIPTION</th></tr>\n",
    "<tr><td>|a|</td><td>torch.abs(a)</td><td>absolute value</td></tr>\n",
    "<tr><td>1/a</td><td>torch.reciprocal(a)</td><td>reciprocal</td></tr>\n",
    "<tr><td>$\\sqrt{a}$</td><td>torch.sqrt(a)</td><td>square root</td></tr>\n",
    "<tr><td>log(a)</td><td>torch.log(a)</td><td>natural log</td></tr>\n",
    "<tr><td>e<sup>a</sup></td><td>torch.exp(a)</td><td>exponential</td></tr>\n",
    "<tr><td>12.34  ==>  12.</td><td>torch.trunc(a)</td><td>truncated integer</td></tr>\n",
    "<tr><td>12.34  ==>  0.34</td><td>torch.frac(a)</td><td>fractional component</td></tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "<table style=\"display: inline-block\">\n",
    "<caption style=\"text-align: center\"><strong>Trigonometry</strong></caption>\n",
    "<tr><th>OPERATION</th><th>FUNCTION</th><th>DESCRIPTION</th></tr>\n",
    "<tr><td>sin(a)</td><td>torch.sin(a)</td><td>sine</td></tr>\n",
    "<tr><td>cos(a)</td><td>torch.sin(a)</td><td>cosine</td></tr>\n",
    "<tr><td>tan(a)</td><td>torch.sin(a)</td><td>tangent</td></tr>\n",
    "<tr><td>arcsin(a)</td><td>torch.asin(a)</td><td>arc sine</td></tr>\n",
    "<tr><td>arccos(a)</td><td>torch.acos(a)</td><td>arc cosine</td></tr>\n",
    "<tr><td>arctan(a)</td><td>torch.atan(a)</td><td>arc tangent</td></tr>\n",
    "<tr><td>sinh(a)</td><td>torch.sinh(a)</td><td>hyperbolic sine</td></tr>\n",
    "<tr><td>cosh(a)</td><td>torch.cosh(a)</td><td>hyperbolic cosine</td></tr>\n",
    "<tr><td>tanh(a)</td><td>torch.tanh(a)</td><td>hyperbolic tangent</td></tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "<table style=\"display: inline-block\">\n",
    "<caption style=\"text-align: center\"><strong>Summary Statistics</strong></caption>\n",
    "<tr><th>OPERATION</th><th>FUNCTION</th><th>DESCRIPTION</th></tr>\n",
    "<tr><td>$\\sum a$</td><td>torch.sum(a)</td><td>sum</td></tr>\n",
    "<tr><td>$\\bar a$</td><td>torch.mean(a)</td><td>mean</td></tr>\n",
    "<tr><td>a<sub>max</sub></td><td>torch.max(a)</td><td>maximum</td></tr>\n",
    "<tr><td>a<sub>min</sub></td><td>torch.min(a)</td><td>minimum</td></tr>\n",
    "<tr><td colspan=\"3\">torch.max(a,b) returns a tensor of size a<br>containing the element wise max between a and b</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487b98ba",
   "metadata": {},
   "source": [
    "## 3) MNIST with fully connected neural net\n",
    "\n",
    "This part loosely follows Lectures 27-31 of PDMIPT. Some references:\n",
    "* Portilla's PDMIPT course, Lects. 27-31. Notebook: https://github.com/drgona/Pytorch_bootcamp_Udemy/blob/master/03-CNN-Convolutional-Neural-Networks/00-MNIST-ANN-Code-Along.ipynb.\n",
    "* Susmelj repo on good design patterns with PyTorch: https://github.com/IgorSusmelj/pytorch-styleguide\n",
    "\n",
    "\n",
    "**Comments:**\n",
    "- Portilla loads MNIST from the torchvision (v.0.2.2) package. See yml file given, or Lects. 3-4.\n",
    "- Portilla uses toch v.1.1.0. I installed 1.8.0 (as of writing, we're at 1.12.0, Colab uses 1.11.0).\n",
    "- Pierian Data have a PyTorch bootcamp. The course files can be downloaded from:\n",
    "    https://github.com/drgona/Pytorch_bootcamp_Udemy\n",
    "    \n",
    "**To do:**\n",
    "There are several points to cover:\n",
    "* How to implement a neural net in PyTorch.\n",
    "* How to write a training function.\n",
    "* How to save/load a model.\n",
    "* Is there a Sequential class as in Keras?\n",
    "* Automatic differentiation and gradients. This is apparently the crux of why PyTorch is better than TF2, but nobody addresses this material in depth.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72e01cf",
   "metadata": {},
   "source": [
    "#### Imports\n",
    "\n",
    "Importing *torch.nn* and *torch.nn.functional* aside will add efficiency to our code.\n",
    "\n",
    "**Remark:** It seems to be recommended to use DataLoader() with Torch when doing batch training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1517b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e497d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5536edd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19e5d02e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Module in module torch.nn.modules.module:\n",
      "\n",
      "class Module(builtins.object)\n",
      " |  Base class for all neural network modules.\n",
      " |  \n",
      " |  Your models should also subclass this class.\n",
      " |  \n",
      " |  Modules can also contain other Modules, allowing to nest them in\n",
      " |  a tree structure. You can assign the submodules as regular attributes::\n",
      " |  \n",
      " |      import torch.nn as nn\n",
      " |      import torch.nn.functional as F\n",
      " |  \n",
      " |      class Model(nn.Module):\n",
      " |          def __init__(self):\n",
      " |              super(Model, self).__init__()\n",
      " |              self.conv1 = nn.Conv2d(1, 20, 5)\n",
      " |              self.conv2 = nn.Conv2d(20, 20, 5)\n",
      " |  \n",
      " |          def forward(self, x):\n",
      " |              x = F.relu(self.conv1(x))\n",
      " |              return F.relu(self.conv2(x))\n",
      " |  \n",
      " |  Submodules assigned in this way will be registered, and will have their\n",
      " |  parameters converted too when you call :meth:`to`, etc.\n",
      " |  \n",
      " |  :ivar training: Boolean represents whether this module is in training or\n",
      " |                  evaluation mode.\n",
      " |  :vartype training: bool\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__ = _call_impl(self, *input, **kwargs)\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Default dir() implementation.\n",
      " |  \n",
      " |  __getattr__(self, name: str) -> Union[torch.Tensor, ForwardRef('Module')]\n",
      " |  \n",
      " |  __init__(self)\n",
      " |      Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name: str, value: Union[torch.Tensor, ForwardRef('Module')]) -> None\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_module(self, name: str, module: Union[ForwardRef('Module'), NoneType]) -> None\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          module (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`nn-init-doc`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> @torch.no_grad()\n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  bfloat16(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  buffers(self, recurse: bool = True) -> Iterator[torch.Tensor]\n",
      " |      Returns an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf), buf.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self: ~T) -> ~T\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self: ~T) -> ~T\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  extra_repr(self) -> str\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should re-implement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  float(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to float datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  forward = _forward_unimplemented(self, *input: Any) -> None\n",
      " |      Defines the computation performed at every call.\n",
      " |      \n",
      " |      Should be overridden by all subclasses.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |  \n",
      " |  half(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict: 'OrderedDict[str, Tensor]', strict: bool = True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      Args:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |      \n",
      " |      Returns:\n",
      " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      " |              * **missing_keys** is a list of str containing the missing keys\n",
      " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
      " |  \n",
      " |  modules(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      " |  \n",
      " |  named_buffers(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n",
      " |      Returns an iterator over module buffers, yielding both the\n",
      " |      name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>    if name in ['running_var']:\n",
      " |          >>>        print(buf.size())\n",
      " |  \n",
      " |  named_children(self) -> Iterator[Tuple[str, ForwardRef('Module')]]\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo: Union[Set[ForwardRef('Module')], NoneType] = None, prefix: str = '')\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      " |  \n",
      " |  named_parameters(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.nn.parameter.Parameter]]\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter]\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param), param.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      This function is deprecated in favor of :meth:`nn.Module.register_full_backward_hook` and\n",
      " |      the behavior of this function will change in future versions.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_buffer(self, name: str, tensor: Union[torch.Tensor, NoneType], persistent: bool = True) -> None\n",
      " |      Adds a buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the module's state. Buffers, by\n",
      " |      default, are persistent and will be saved alongside parameters. This\n",
      " |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
      " |      only difference between a persistent buffer and a non-persistent buffer\n",
      " |      is that the latter will not be a part of this module's\n",
      " |      :attr:`state_dict`.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor): buffer to be registered.\n",
      " |          persistent (bool): whether the buffer is part of this module's\n",
      " |              :attr:`state_dict`.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None or modified output\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the output. It can modify the input inplace but\n",
      " |      it will not have effect on forward since this is called after\n",
      " |      :func:`forward` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input) -> None or modified input\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the input. User can either return a tuple or a\n",
      " |      single modified value in the hook. We will wrap the value into a tuple\n",
      " |      if a single value is returned(unless that value is already a tuple).\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_full_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to module\n",
      " |      inputs are computed. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> tuple(Tensor) or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` are tuples that contain the gradients\n",
      " |      with respect to the inputs and outputs respectively. The hook should\n",
      " |      not modify its arguments, but it can optionally return a new gradient with\n",
      " |      respect to the input that will be used in place of :attr:`grad_input` in\n",
      " |      subsequent computations. :attr:`grad_input` will only correspond to the inputs given\n",
      " |      as positional arguments and all kwarg arguments are ignored. Entries\n",
      " |      in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor\n",
      " |      arguments.\n",
      " |      \n",
      " |      .. warning ::\n",
      " |          Modifying inputs or outputs inplace is not allowed when using backward hooks and\n",
      " |          will raise an error.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_parameter(self, name: str, param: Union[torch.nn.parameter.Parameter, NoneType]) -> None\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          param (Parameter): parameter to be added to the module.\n",
      " |  \n",
      " |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n",
      " |      Change if autograd should record operations on parameters in this\n",
      " |      module.\n",
      " |      \n",
      " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
      " |      in-place.\n",
      " |      \n",
      " |      This method is helpful for freezing part of the module for finetuning\n",
      " |      or training parts of a model individually (e.g., GAN training).\n",
      " |      \n",
      " |      Args:\n",
      " |          requires_grad (bool): whether autograd should record operations on\n",
      " |                                parameters in this module. Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  share_memory(self: ~T) -> ~T\n",
      " |  \n",
      " |  state_dict(self, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing a whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(memory_format=torch.channels_last)\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point or complex :attr:`dtype`s. In addition, this method will\n",
      " |      only cast the floating point or complex parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point or complex dtype of\n",
      " |              the parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |          memory_format (:class:`torch.memory_format`): the desired memory\n",
      " |              format for 4D parameters and buffers in this module (keyword\n",
      " |              only argument)\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.3741+0.j,  0.2382+0.j],\n",
      " |                  [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\n",
      " |          >>> linear(torch.ones(3, 2, dtype=torch.cdouble))\n",
      " |          tensor([[0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\n",
      " |  \n",
      " |  train(self: ~T, mode: bool = True) -> ~T\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
      " |                       mode (``False``). Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      Args:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  xpu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the XPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on XPU while being optimized.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self, set_to_none: bool = False) -> None\n",
      " |      Sets gradients of all model parameters to zero. See similar function\n",
      " |      under :class:`torch.optim.Optimizer` for more context.\n",
      " |      \n",
      " |      Args:\n",
      " |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
      " |              See :meth:`torch.optim.Optimizer.zero_grad` for details.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  T_destination = ~T_destination\n",
      " |  \n",
      " |  __annotations__ = {'__call__': typing.Callable[..., typing.Any], '_is_...\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf675595",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(0,1,0.01)\n",
    "sin_t = np.sin(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2f91a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20dedd2b8e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.array([t,sin_t]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bd7e4e",
   "metadata": {},
   "source": [
    "### 3.a - Loading the data\n",
    "Load the reduced MNIST NumPy arrays created previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ea1b772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "X_train = np.load(file = \"MNIST_Small_Training_FlatImg.npy\")\n",
    "y_train = np.load(file = \"MNIST_Small_Training_Labels.npy\")\n",
    "# Testing\n",
    "X_test = np.load(file = \"MNIST_Small_Test_FlatImg.npy\")\n",
    "y_test = np.load(file = \"MNIST_Small_Test_Labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06300d56",
   "metadata": {},
   "source": [
    "Now ***rescale*** and ***convert*** the training and test images to torch tensors. We'll also split the training set to training and validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "817b8d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert and rescale flattened images\n",
    "x_train = T.tensor(data = (X_train[0:15000]/255), dtype=T.float32)\n",
    "x_val = T.tensor(data = (X_train[15000:18000]/255), dtype=T.float32)\n",
    "x_test = T.tensor(data = (X_test/255), dtype=T.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ad84d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "NOTE: In PyTorch 1.11 (Colab's version), it was enough to convert the labels to tensors.\n",
    "      The version in which I run this notebook is 1.8, and seems to require the labels\n",
    "      to be LongTensors (long ints).\n",
    "y_train_ = T.tensor(data=y_train[:15000])\n",
    "y_val_ = T.tensor(data=y_train[15000:18000])\n",
    "y_test_ = T.tensor(data=y_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60e6665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ = T.LongTensor(data=y_train[:15000])\n",
    "y_val_ = T.LongTensor(data=y_train[15000:18000])\n",
    "y_test_ = T.LongTensor(data=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff76c7a",
   "metadata": {},
   "source": [
    "### 3.b - Fully connected nets in PyTorch\n",
    "\n",
    "**Main points:**\n",
    "1) The ANN class is typically inherited from the ***torch.nn.model()*** class.\n",
    "2) Layers of the ANN, including the no. of units and dimensions of inputs/outputs.\n",
    "3) Forward method in the\n",
    "\n",
    "**Questions:**\n",
    "- How do you convert the labels into one-hot vectors? Use nn.functional.one_hot()\n",
    "- What is the *super()* statement used in building the neural net?\n",
    "- How do you conceptualize the attributes od the model and the *forward()* method?\n",
    "- Why are the loss function and the optimizer outside the network? Can you gather everything in one object as in Keras' *Sequential()*?\n",
    "- Why's Portilla using log_softmax for the output?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd28ae6e",
   "metadata": {},
   "source": [
    "#### 2 - Main class\n",
    "\n",
    "Our first example will consist of 3 fully connected layers:\n",
    "* Input layer 1 will take-in flattened images and contain 128 units.\n",
    "* Second layer will contain 64 units.\n",
    "* Output layer will output 10 probable classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4faee915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_dim = 784\n",
    "layer_1_n_units = 128\n",
    "layer_2_n_units = 64\n",
    "output_dim = 10\n",
    "layer_dim_list = [input_dim, layer_1_n_units, layer_2_n_units, output_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58f10074",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    '''\n",
    "        ANN class, fully connected with 3 layers:\n",
    "        * Input layer 1 will take-in flattened images and contain 128 units.\n",
    "        * Second layer will contain 64 units.\n",
    "        * Output layer will output 10 probabilities, one for each classes.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, layer_dim_list=[784,128,64,10]):\n",
    "        '''\n",
    "            ARGUMENT: layer_dim_list = [input_dim, layer_1_n_units, layer_2_n_units, output_dim], list of integers.\n",
    "        '''\n",
    "        super().__init__() # What is this for?\n",
    "        self.units_list = layer_dim_list\n",
    "        self.layer_1_fc = nn.Linear(in_features = self.units_list[0], out_features=self.units_list[1])\n",
    "        self.layer_2_fc = nn.Linear(in_features = self.units_list[1], out_features=self.units_list[2])\n",
    "        self.layer_3_fc = nn.Linear(in_features = self.units_list[2], out_features=self.units_list[3])\n",
    "        \n",
    "    def forward(self, X):\n",
    "        '''\n",
    "            Forward propagation function. Activations by layer:\n",
    "            * Layer 1: ReLU; * Layer 2: ReLU; * Layer 3: log_softmax\n",
    "            ARGUMENT: Data X (toch.tensor).\n",
    "              OUTPUT: Prediction.\n",
    "        '''\n",
    "        X = F.relu(self.layer_1_fc(X)) \n",
    "        X = F.relu(self.layer_2_fc(X))\n",
    "        X = self.layer_3_fc(X)\n",
    "        \n",
    "        return F.log_softmax(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38828f6f",
   "metadata": {},
   "source": [
    "Now we instantiate the model, the loss and the optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc582c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = ANN(layer_dim_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56dafeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function:\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# Optimizer:\n",
    "optimizer = T.optim.Adam(params = model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fdc6942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[784, 128, 64, 10]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.units_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48555a5",
   "metadata": {},
   "source": [
    "Next, define the loss function and optimizer for the model. For the latter, ***one explicitly ties the model parameters to the optimizer***. Notes:\n",
    "* The losses are in the ***torch.nn*** module.\n",
    "* The optimizers are in the ***torch.optim*** module.\n",
    "* The *torch.Module()* class has a method **parameters()** that generates an iterator for the optimizer. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81755f83",
   "metadata": {},
   "source": [
    "#### 3- Training code:\n",
    "\n",
    "Quite reminiscent of the TF1 approach. I'm modifying the code from Portilla's notebook below. I don't like how he designed it.\n",
    "\n",
    "**To do:**\n",
    "* Are there built-in verbose functions as in Keras for PyTorch?\n",
    "* Why is the *item()* method used this often?\n",
    "* I don't understand the second loop over batches. I had the same issue in TensorFlow.\n",
    "* The central instructions for one training step (for one batch at a given epoch) are:\n",
    "\n",
    "        optimizer.zero_grad() # Set all gradients to 0\n",
    "        loss.backward() # Perform backpropagation\n",
    "        optimizer.step() # What is this\n",
    "        \n",
    "   Clarify what these do. They're pretty standard (see the learn method of P. Tabor's DQN agent in PyTorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7efd2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zaj20\\AppData\\Local\\Temp\\ipykernel_5264\\1048247494.py:30: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1; Loss:     0.3350; Accuracy:      79.33%\n",
      "Epoch: 2; Loss:     0.2245; Accuracy:      90.82%\n",
      "Epoch: 3; Loss:     0.1605; Accuracy:      92.69%\n",
      "Epoch: 4; Loss:     0.1251; Accuracy:      94.03%\n",
      "Epoch: 5; Loss:     0.1019; Accuracy:      95.09%\n",
      "Epoch: 6; Loss:     0.0791; Accuracy:      96.00%\n",
      "Epoch: 7; Loss:     0.0620; Accuracy:      96.87%\n",
      "Epoch: 8; Loss:     0.0466; Accuracy:      97.43%\n",
      "Epoch: 9; Loss:     0.0357; Accuracy:      98.01%\n",
      "Epoch: 10; Loss:     0.0279; Accuracy:      98.43%\n",
      "Training finished. Elapsed time = 0:00:06.098474\n"
     ]
    }
   ],
   "source": [
    "##### TRAINING #####\n",
    "\n",
    "# Initializations\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int((len(x_train))/batch_size)\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "# Timer init.\n",
    "train_begin_time = datetime.now()\n",
    "\n",
    "# Loop over epochs:\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    train_correct_samples = 0 \n",
    "    val_correct_samples = 0\n",
    "    \n",
    "    # Loop over batches\n",
    "    for i_batch in range(n_batches):\n",
    "        '''\n",
    "            Might have to modify this for validation later\n",
    "        '''\n",
    "        # Pick batches\n",
    "        batch_x = x_train[i_batch*batch_size:(i_batch+1)*batch_size]\n",
    "        batch_y = y_train_[i_batch*batch_size:(i_batch+1)*batch_size]\n",
    "        \n",
    "        # Predict labels and compute loss\n",
    "        batch_y_pred = model(batch_x) # CLARIFY.\n",
    "        loss = loss_fn(batch_y_pred, batch_y) # CLARIFY.\n",
    "        \n",
    "        # Counter no. of correct predictions and current accuracy\n",
    "        predicted_digits = T.argmax(batch_y_pred, dim =1)\n",
    "        batch_correct = (predicted_digits == batch_y).sum().item()\n",
    "        train_correct_samples += batch_correct\n",
    "        current_accuracy = (train_correct_samples*100)/((i_batch+1)*batch_size)\n",
    "        \n",
    "        # Perform one optimization step\n",
    "        optimizer.zero_grad() # CLARIFY\n",
    "        loss.backward() # CLARIFY\n",
    "        optimizer.step() # CLARIFY\n",
    "\n",
    "        # Verbose\n",
    "        '''\n",
    "        if ( (i_batch+1) %25) == 0:\n",
    "          # Modify for better formatting\n",
    "          print(f\"Epoch: {epoch+1}; Batch: {i_batch+1}; Loss: {loss.item():10.4f}; Accuracy: {current_accuracy:10.2f}%\")\n",
    "        '''\n",
    "            \n",
    "    # END OF BATCH LOOP\n",
    "    print(f\"Epoch: {epoch+1}; Loss: {loss.item():10.4f}; Accuracy: {current_accuracy:10.2f}%\")\n",
    "    \n",
    "    # Update train loss & accuracy for the epoch\n",
    "    train_losses.append(loss.item())\n",
    "    train_correct.append(train_correct_samples)\n",
    "\n",
    "# END EPOCH LOOP\n",
    "\n",
    "print(f\"Training finished. Elapsed time = {datetime.now()-train_begin_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "baf5b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, optimizer, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "baba42f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.36283501982688904,\n",
       " 0.24444255232810974,\n",
       " 0.17537030577659607,\n",
       " 0.13065586984157562,\n",
       " 0.10290651023387909,\n",
       " 0.08298884332180023,\n",
       " 0.06564819067716599,\n",
       " 0.05184834077954292,\n",
       " 0.03955361992120743,\n",
       " 0.03164398670196533]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e552d951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20deff18040>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(10), train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "944228c7-8e9d-4556-8b90-e1d659bc02aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20deff68f40>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(10), train_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f5fffd",
   "metadata": {},
   "source": [
    "**Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "192acc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zaj20\\AppData\\Local\\Temp\\ipykernel_5264\\1048247494.py:30: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(X)\n"
     ]
    }
   ],
   "source": [
    "n_val_batches = int(len(x_val)/batch_size)\n",
    "val_losses = []\n",
    "val_correct = []\n",
    "\n",
    "with T.no_grad():\n",
    "    \n",
    "    val_correct_samples = 0\n",
    "\n",
    "    # Validation loop\n",
    "    for i_batch in range(n_val_batches):\n",
    "        \n",
    "        # Pick batches\n",
    "        batch_x = x_val[i_batch*batch_size:(i_batch+1)*batch_size]\n",
    "        batch_y = y_val_[i_batch*batch_size:(i_batch+1)*batch_size]\n",
    "\n",
    "        # Predict labels and compute loss\n",
    "        batch_y_pred = model(batch_x) \n",
    "\n",
    "        # Counter no. of correct predictions and current accuracy\n",
    "        predicted_digits = T.argmax(batch_y_pred, dim =1)\n",
    "        batch_correct = (predicted_digits == batch_y).sum().item()\n",
    "        val_correct_samples += batch_correct\n",
    "        #current_accuracy = train_correct_samples/((i_batch+1)*batch_size)\n",
    "\n",
    "    # END VALIDATION LOOP\n",
    "    accuracy = (100*val_correct_samples)/len(x_val)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e759f305",
   "metadata": {},
   "source": [
    "**Notes on softmax and backpropagation in PyTorch:**\n",
    "\n",
    "My approach for a multi-class classification problem is to convert the labels into one-hot vectors (vectors of integers), and use softmax as the activation of the output layer. Here's my forward function:\n",
    "\n",
    "            def forward(self, X):\n",
    "                X = F.relu(self.layer_1_fc(X)) \n",
    "                X = F.relu(self.layer_2_fc(X))\n",
    "                X = self.layer_3_fc(X)\n",
    "\n",
    "                return F.log_softmax(X)\n",
    "                \n",
    "Say I setup my batch by hand:\n",
    "\n",
    "            batch_x = x_train[i_batch*batch_size:(i_batch+1)*batch_size]\n",
    "            batch_y = y_cat_train[i_batch*batch_size:(i_batch+1)*batch_size]\n",
    "            \n",
    "Then I predict the probabilities:\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327749fc-5e1c-4afe-9757-719f5422427d",
   "metadata": {},
   "source": [
    "## 4) MNIST with CNN\n",
    "\n",
    "This part loosely follows Lectures 31-38 of PDMIPT. Here's a reference:\n",
    "\n",
    "https://github.com/drgona/Pytorch_bootcamp_Udemy/blob/master/03-CNN-Convolutional-Neural-Networks/01-MNIST-with-CNN.ipynb\n",
    "\n",
    "\n",
    "**To do:**\n",
    "Main points to cover:\n",
    "* Specific functions for CNN layers: Convolutional, pooling, loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac56656a-fd83-4572-8c03-abf9f8aefc88",
   "metadata": {},
   "source": [
    "#### Imports\n",
    "\n",
    "Importing *torch.nn* and *torch.nn.functional* aside will add efficiency to our code.\n",
    "\n",
    "**Remark:** It seems to be recommended to use DataLoader() with Torch when doing batch training. I don't use it here though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f08f4d-de73-4640-82f7-2b23edfef7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7130f3b5-c707-4c5a-9c63-610835864cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "360b4adc-8df7-4c3b-a4dc-b18be90f49c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb1c3f9-9fa6-4031-923b-4e0a34f6a65f",
   "metadata": {},
   "source": [
    "Next, load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fafd7071-0029-4982-b122-3917046bdca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "X_train = np.load(file = \"MNIST_Small_Training_FlatImg.npy\")\n",
    "y_train = np.load(file = \"MNIST_Small_Training_Labels.npy\")\n",
    "# Testing\n",
    "X_test = np.load(file = \"MNIST_Small_Test_FlatImg.npy\")\n",
    "y_test = np.load(file = \"MNIST_Small_Test_Labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c299d41a-cadb-4fb0-b5fc-77fe604ec295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rescale flattened images and convert them to 28x28 tensors\n",
    "x_train = T.tensor(data = (X_train[0:15000]/255), dtype=T.float32)\n",
    "x_val = T.tensor(data = (X_train[15000:18000]/255), dtype=T.float32)\n",
    "x_test = T.tensor(data = (X_test/255), dtype=T.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3782942-bb78-4cd9-bde4-1bac113a91bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ = T.LongTensor(data=y_train[:15000])\n",
    "y_val_ = T.LongTensor(data=y_train[15000:18000])\n",
    "y_test_ = T.LongTensor(data=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca650beb-e004-4b5c-948d-602078d30ffb",
   "metadata": {},
   "source": [
    "#### CNN construction\n",
    "\n",
    "We reproduce the following Keras model:\n",
    "\n",
    "            \n",
    "            cnn_model = Sequential()\n",
    "\n",
    "            ## Add layers, input->conv->maxpool->flatten->dense->dense\n",
    "            cnn_model.add(Conv2D(filters= 32, kernel_size= (4,4),\\\n",
    "                                 activation = \"relu\", input_shape=(n_pxs,n_pxs,1))) # Conv layer\n",
    "            cnn_model.add(MaxPool2D(pool_size = (2,2)))                             # MaxPool layer\n",
    "            cnn_model.add(Flatten())                                                # Flattening\n",
    "            cnn_model.add(Dense(units = 128, activation = \"relu\"))                  # FC 1\n",
    "            cnn_model.add(Dense(units = 10, activation = \"softmax\"))                # FC 2\n",
    "\n",
    "            # Compile model\n",
    "            cnn_model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "Here we'll define many more network hyperparameters, and pay special attention to the coherence of the output dimensions of our layers. A good feature of the PyTorch documentation is that they provide general formulas for these dimensions in their docs:\n",
    "\n",
    "* **2d-Convolutional layer:** This is ***nn.Conv2D()***, https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html. Here's the signature:\n",
    "\n",
    "            torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "\n",
    "* **2d-Maxpool layer:** This is ***nn.MaxPool2D()***, https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html.\n",
    "\n",
    "\n",
    "            torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7fcd744-a59d-4b97-afa0-322d9c60d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    '''\n",
    "        Small CNN class: input->Conv2D->MaxPool2D->FC1->FC2\n",
    "        See __init__() for input.\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, img_dims = [28, 28, 1], \\\n",
    "                 conv_dims = [4, 4, 1, 1, 32], \\\n",
    "                 pool_dims = [2, 2], \\\n",
    "                 fc1_units = 128, n_classes=10):\n",
    "        '''\n",
    "            ARGUMENTS:\n",
    "            Lists of dimensions for each layer of CNN. Default is MNIST for input.\n",
    "            Convention as follows:\n",
    "            * img_dims = [in_height, in_width, in_channels], dims of input images.\n",
    "            * conv_dims = [conv_ker_ht, conv_ker_wd, conv_str_ht, conv_str_wd, n_conv_filters]\n",
    "            * pool_dims = [pool_ver, pool_hor]. Here stride size = kernel size.\n",
    "            * fc1_units = no. of neurons in fully connected layer.\n",
    "            * n_classes = no. of classes or dim. of output layer.\n",
    "            \n",
    "            \n",
    "        '''\n",
    "        super().__init__()\n",
    "        \n",
    "        #####################\n",
    "        ## HYPERPARAMETERS ##\n",
    "        #####################\n",
    "        \n",
    "        # Input image dimensions\n",
    "        self.in_height = img_dims[0]\n",
    "        self.in_width = img_dims[1]\n",
    "        self.in_channels = img_dims[2]\n",
    "        \n",
    "        # Conv. layer hyperparam.\n",
    "        ## Using 0 padding \n",
    "        self.conv_ker_ht = conv_dims[0]\n",
    "        self.conv_ker_wd = conv_dims[1]\n",
    "        self.conv_str_ht = conv_dims[2]\n",
    "        self.conv_str_wd = conv_dims[3]\n",
    "        self.n_conv_filters = conv_dims[4]\n",
    "        self.conv_out_ht = int((self.in_height-self.conv_ker_ht)/ self.conv_str_ht)+1\n",
    "        self.conv_out_wd = int((self.in_width-self.conv_ker_wd)/ self.conv_str_wd)/+1\n",
    "        \n",
    "        # Pooling layer hyperparam.\n",
    "        ## Using 0 padding, stride size = \"kernel\" size\n",
    "        self.pool_ver = pool_dims[0]\n",
    "        self.pool_hor = pool_dims[1]\n",
    "        \n",
    "        # FC1 layer dim\n",
    "        self.fc1_dim_in = self.n_conv_filters*int(self.conv_out_ht/self.pool_ver)\\\n",
    "                            *int(self.conv_out_wd/self.pool_hor)\n",
    "        self.fc1_units = fc1_units\n",
    "        \n",
    "        # Out (FC2) layer dim (no. of classes)\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        #####################\n",
    "        ##      LAYERS     ##\n",
    "        #####################\n",
    "        \n",
    "        #self.cnn_dim_list = cnn_dim_list # useful? necessary?\n",
    "        '''\n",
    "            CONVOLUTIONAL LAYER\n",
    "            torch.nn.Conv2d(in_channels, out_channels, kernel_size, \\\n",
    "                            stride=1, padding=0, dilation=1, groups=1, \\\n",
    "                            bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "            in_channels and out_channels are ints, not \n",
    "        '''\n",
    "        self.layer_1_conv = nn.Conv2d(in_channels = self.in_channels, \\\n",
    "                                      out_channels = self.n_conv_filters,\\\n",
    "                                      kernel_size = (self.conv_ker_ht, self.conv_ker_wd),\\\n",
    "                                      stride = (self.conv_str_ht, self.conv_str_wd), \\\n",
    "                                      padding=0)\n",
    "        '''\n",
    "            MAXPOOL LAYER\n",
    "            torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, \\\n",
    "                                dilation=1, return_indices=False, ceil_mode=False)\n",
    "        '''\n",
    "        self.layer_2_maxpl = nn.MaxPool2d(kernel_size= (self.pool_ver, self.pool_hor), \\\n",
    "                                          stride = (self.pool_ver, self.pool_hor), padding=0)\n",
    "        self.layer_3_fc = nn.Linear(in_features=self.fc1_dim_in, out_features=self.fc1_units)\n",
    "        self.layer_4_fc = nn.Linear(in_features=self.fc1_units, out_features=self.n_classes)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        X = self.layer_1_conv(X)\n",
    "        X = self.layer_2_maxpl(X)\n",
    "        X = F.relu(self.layer_3_fc(X.reshape(-1,self.fc1_dim_in))) # Flatten images here\n",
    "        X = F.log_softmax(self.layer_4_fc(X), dim =1)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94493ee7-0dba-4872-bb5d-74173680c49f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d5da999-a8d4-4aff-8ed5-668963dbc479",
   "metadata": {},
   "source": [
    "#### Instantiating the model\n",
    "\n",
    "To avoid conflicts with the previous ANN, the CNN model will be called *cnn_model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e6b7357-4c48-48a2-963a-7f5b6ae396db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refresh model\n",
    "del cnn_model, cnn_loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bca3a196-1edc-4b7b-a0d2-039ebb37db62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nconv_out_ht = n_height-conv_ker_ht +1\\nconv_out_wd = n_width-conv_ker_wd +1\\n\\nfc1_dim_in = np.int(conv_out_ht/pool_ver)*             np.int(conv_out_wd/pool_hor)*             conv_n_filters\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################\n",
    "##### Network hyperparameters #####\n",
    "###################################\n",
    "\n",
    "# Input/Final Output\n",
    "n_height = 28\n",
    "n_width = 28\n",
    "n_channels = 1\n",
    "\n",
    "# Conv. layer\n",
    "conv_ker_ht = 4\n",
    "conv_ker_wd = 4\n",
    "conv_n_filters = 32\n",
    "\n",
    "# MaxPool layer\n",
    "pool_ver = 2 \n",
    "pool_hor = 2\n",
    "\n",
    "# Dims of 2 fully connected layers\n",
    "fc1_dim_out = 128\n",
    "n_classes = 10\n",
    "\n",
    "'''\n",
    "conv_out_ht = n_height-conv_ker_ht +1\n",
    "conv_out_wd = n_width-conv_ker_wd +1\n",
    "\n",
    "fc1_dim_in = np.int(conv_out_ht/pool_ver)*\\\n",
    "             np.int(conv_out_wd/pool_hor)*\\\n",
    "             conv_n_filters\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0974b6bc-0a25-468d-b20c-0b61fc5aa0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "cnn_model = CNN(img_dims=[n_height, n_width, n_channels],\\\n",
    "                conv_dims=[conv_ker_ht, conv_ker_wd, 1, 1, conv_n_filters],\\\n",
    "                pool_dims=[pool_ver, pool_hor], \\\n",
    "                fc1_units=fc1_dim_out, n_classes = n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "39f6ca33-339b-4d0c-8941-5a6eb786c8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function:\n",
    "cnn_loss_fn = nn.CrossEntropyLoss()\n",
    "# Optimizer:\n",
    "optimizer = T.optim.Adam(params = cnn_model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64e2e89-e62b-4b29-a8a4-ff66a44692ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Training code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "573d030d-7615-41bd-9713-651546c1cec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1; Loss:     0.2577; Accuracy:      84.77%\n",
      "Epoch: 2; Loss:     0.1320; Accuracy:      93.10%\n",
      "Epoch: 3; Loss:     0.0794; Accuracy:      95.23%\n",
      "Epoch: 4; Loss:     0.0582; Accuracy:      96.55%\n",
      "Epoch: 5; Loss:     0.0450; Accuracy:      97.63%\n",
      "Epoch: 6; Loss:     0.0378; Accuracy:      98.39%\n",
      "Epoch: 7; Loss:     0.0247; Accuracy:      98.83%\n",
      "Epoch: 8; Loss:     0.0136; Accuracy:      99.24%\n",
      "Epoch: 9; Loss:     0.0104; Accuracy:      99.58%\n",
      "Epoch: 10; Loss:     0.0097; Accuracy:      99.78%\n",
      "Training finished. Elapsed time = 0:02:08.680822\n"
     ]
    }
   ],
   "source": [
    "##### TRAINING #####\n",
    "\n",
    "# Initializations\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int((len(x_train))/batch_size)\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "# Timer init.\n",
    "train_begin_time = datetime.now()\n",
    "\n",
    "# Loop over epochs:\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    train_correct_samples = 0 \n",
    "    val_correct_samples = 0\n",
    "    \n",
    "    # Loop over batches\n",
    "    for i_batch in range(n_batches):\n",
    "        '''\n",
    "            Might have to modify this for validation later\n",
    "        '''\n",
    "        # Pick batches\n",
    "        batch_x = x_train.reshape(len(x_train), n_channels, n_height,n_width)\\\n",
    "                            [i_batch*batch_size:(i_batch+1)*batch_size]\n",
    "        batch_y = y_train_[i_batch*batch_size:(i_batch+1)*batch_size]\n",
    "        \n",
    "        # Predict labels and compute loss\n",
    "        batch_y_pred = cnn_model(batch_x) # CLARIFY.\n",
    "        loss = cnn_loss_fn(batch_y_pred, batch_y) # CLARIFY.\n",
    "        \n",
    "        # Counter no. of correct predictions and current accuracy\n",
    "        predicted_digits = T.argmax(batch_y_pred, dim =1)\n",
    "        batch_correct = (predicted_digits == batch_y).sum().item()\n",
    "        train_correct_samples += batch_correct\n",
    "        current_accuracy = (train_correct_samples*100)/((i_batch+1)*batch_size)\n",
    "        \n",
    "        # Perform one optimization step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "        \n",
    "    # END OF BATCH LOOP\n",
    "    print(f\"Epoch: {epoch+1}; Loss: {loss.item():10.4f}; Accuracy: {current_accuracy:10.2f}%\")\n",
    "    \n",
    "    # Update train loss & accuracy for the epoch\n",
    "    train_losses.append(loss.item())\n",
    "    train_correct.append(train_correct_samples)\n",
    "\n",
    "# END EPOCH LOOP\n",
    "\n",
    "print(f\"Training finished. Elapsed time = {datetime.now()-train_begin_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "668b72bc-f67d-4131-8f2f-c95cf16f5c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x186c4bf50a0>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(10), train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34ebe2a7-2b4a-40ac-a98e-c8d7dcfb1b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x186c4c44250>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(10), train_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e44dda-b832-487b-8c9b-e309729198e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c95b5b8f-ee28-448d-9654-2a0327bb8868",
   "metadata": {},
   "source": [
    "#### Validation code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99e748f2-3963-48e8-a8f4-db8b5d724c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 96.6%\n"
     ]
    }
   ],
   "source": [
    "n_val_batches = int(len(x_val)/batch_size)\n",
    "val_losses = []\n",
    "val_correct = []\n",
    "\n",
    "with T.no_grad():\n",
    "    \n",
    "    val_correct_samples = 0\n",
    "\n",
    "    # Validation loop\n",
    "    for i_batch in range(n_val_batches):\n",
    "        \n",
    "        # Pick batches\n",
    "        batch_x = x_val.reshape(len(x_val), n_channels, n_height, n_width)[i_batch*batch_size:(i_batch+1)*batch_size]\n",
    "        batch_y = y_val_[i_batch*batch_size:(i_batch+1)*batch_size]\n",
    "\n",
    "        # Predict labels and compute loss\n",
    "        batch_y_pred = cnn_model(batch_x) \n",
    "\n",
    "        # Counter no. of correct predictions and current accuracy\n",
    "        predicted_digits = T.argmax(batch_y_pred, dim =1)\n",
    "        batch_correct = (predicted_digits == batch_y).sum().item()\n",
    "        val_correct_samples += batch_correct\n",
    "        #current_accuracy = train_correct_samples/((i_batch+1)*batch_size)\n",
    "\n",
    "    # END VALIDATION LOOP\n",
    "    accuracy = (100*val_correct_samples)/len(x_val)\n",
    "    print(f\"Accuracy on validation set: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafb9fe4-7755-4f0c-8285-79b17aa7b14a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb9c0a4f-0898-4ebc-b977-067b16baf770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x186c4c84f40>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_id = np.random.randint(0,len(x_test))\n",
    "plt.imshow(x_test[img_id].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a848857a-26b5-4676-9842-74be2d1a6ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted digit is: 3\n"
     ]
    }
   ],
   "source": [
    "img_pred = T.argmax(cnn_model(x_test[img_id].reshape(1,28,28)), dim = 1)\n",
    "print(f\"Predicted digit is: {img_pred.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea15074-63c8-43ab-96bf-926fb6001059",
   "metadata": {},
   "source": [
    "#### Some comments:\n",
    "\n",
    "1)  Here's an intersting difference compared to TensorFlow: When making Conv2D and MaxPool2D layers, you specify only the number of input channels and the number of output channels (TF call this no. of filters). Indeed, as with Keras, you don't need to specify of the height and width pixels. Another note is how torch manages to be more accurate that TF with 1/2 the number of epochs. However, TF seems slightly faster at this specfic task with 20 epochs.\n",
    "\n",
    "2) I had a conceptual mistake previously: Image filters need not be symmetric matrices. A good set of practical and interactive examples can be found at: https://setosa.io/ev/image-kernels/. Note the Sobel filters in particular, which aren't symmetric, but allow one to extract sharp edges. The Blur, Sharpen, Emboss, and Outline filters are symmetric matrices.\n",
    "\n",
    "3) For a theoretical discussion of convolutional and pooling layers, the convolution operation, convergence results for max/min/average pooling, and translation invariance, see chapters 15 and 16 of Calin's \"Deep learning Architectures - A mathematical approach\". In particular, he shows in the proof of Theorem 15.1.1 that the max/min/average pooling operations on functions of real variables define sequences that converge uniformly to the approximated function. Here the index n is the cardinality of the partition of the support, and it works because these operations essentially define simple functions (as in the ones seen in measure theory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e67800-9fb5-446b-935c-4956d47231a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce8db617-aca8-4949-8cd4-526a71509d88",
   "metadata": {},
   "source": [
    "## 4)' Addendum: CNN with DataLoader\n",
    "\n",
    "Adding the use of a dataloader. Still following:\n",
    "\n",
    "https://github.com/drgona/Pytorch_bootcamp_Udemy/blob/master/03-CNN-Convolutional-Neural-Networks/01-MNIST-with-CNN.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bca42c-f97b-4d31-b37f-be7c27348bd9",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e044b2b4-5c82-46b5-a530-0a408aaa4452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31c5eae1-fe52-4fab-a2dc-68ba1b052566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfd14fc3-a9e5-4b0d-b6fb-7e4ec84f56ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50ed3b0-7117-4e32-bc01-ec44e0422b50",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0eaa088-ec27-49c8-b8d4-15bfb418a741",
   "metadata": {},
   "source": [
    "#### Reduced MNIST with Dataset and DataLoader classes\n",
    "\n",
    "First, we load our dataset, we rescale the images, and convert the images and labels to torch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "970a1c12-cd48-4894-b644-76eff0ea5032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "X_train = np.load(file = \"MNIST_Small_Training_FlatImg.npy\")\n",
    "y_train = np.load(file = \"MNIST_Small_Training_Labels.npy\")\n",
    "# Testing\n",
    "X_test = np.load(file = \"MNIST_Small_Test_FlatImg.npy\")\n",
    "y_test = np.load(file = \"MNIST_Small_Test_Labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "273d8bc2-84f4-4361-84f2-6f2b4c4b156d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rescale flattened images and convert them to 28x28 tensors\n",
    "x_train = T.tensor(data = (X_train[0:15000]/255), dtype=T.float32)\n",
    "x_val = T.tensor(data = (X_train[15000:18000]/255), dtype=T.float32)\n",
    "x_test = T.tensor(data = (X_test/255), dtype=T.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "838e20b8-4915-43fe-b8c0-3907021334b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ = T.LongTensor(data=y_train[:15000])\n",
    "y_val_ = T.LongTensor(data=y_train[15000:18000])\n",
    "y_test_ = T.LongTensor(data=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdbad3a-9cf9-42ff-9c6b-b8eaa859fac5",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "Here we use the Dataset and DataLoader classes of *torch.utils.data*. Here is a useful guide:\n",
    "\n",
    "https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel\n",
    "\n",
    "The official documentation (very dense) is at the link:\n",
    "\n",
    "https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
    "\n",
    "Our next step is to write a custom class inherited from Dataset. There are 3 methods to implement:\n",
    "\n",
    "* **The constructor:** To specify the attributes of our dataset. Here these are images and the digits (labels).\n",
    "* **len() overload:** To obtain the number of elements in the dataset. Obviously used when constructing batches.\n",
    "* **getitem() overload:** To use indexing on our dataset and access its contents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e24e2289-aa3d-4f35-bc05-49ce8a1fa806",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_red(Dataset):\n",
    "    '''\n",
    "        Has 2 attributes:\n",
    "        * X (images): Flattened MNIST images, of size (N_samples, 784) and type torch.tensor()\n",
    "        * y (labels): Integers representing the digits in X, of size (N_samples, ) and type torch.LongTensor()\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, images, labels):\n",
    "        # Basics\n",
    "        self.X = images\n",
    "        self.y = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        # For number of samples\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        # For indexing\n",
    "        return (self.X[idx], self.y[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d6d190-c54f-4e1a-b57b-ffb284c986d6",
   "metadata": {},
   "source": [
    "Now we organize our training, validation, and test data into this new class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc8ecd11-e3fb-4c92-8d62-2634cfb74d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_train = MNIST_red(x_train, y_train_)\n",
    "Dataset_val = MNIST_red(x_val, y_val_)\n",
    "Dataset_test = MNIST_red(x_test, y_test_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4d27b5-e344-4425-94d1-bf1992cf34e4",
   "metadata": {},
   "source": [
    "Finally, we instantiate our data loaders for the training and validation (similar to the generators used with Keras). The important arguments are *data*, *batch_size* and *shuffle*. Typically, *DataLoader()* is used with the *Dataset()* class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b476533-e6f6-487c-9379-d41e5d21499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=Dataset_train, batch_size = 100, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39093a32-4adc-46e6-b6d0-eef53f0ff0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(dataset=Dataset_val, batch_size = 100, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49251b07-23d9-4dc5-a9f7-68064dbf8087",
   "metadata": {},
   "source": [
    "These are used respectively in the training and validation code after the constructions of our CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3732dcfd-a848-47f8-9f8e-447c851d196e",
   "metadata": {},
   "source": [
    "#### CNN construction\n",
    "\n",
    "Same CNN as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66907fd7-3867-4451-acce-3e122ea39b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    '''\n",
    "        Small CNN class: input->Conv2D->MaxPool2D->FC1->FC2\n",
    "        See __init__() for input.\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, img_dims = [28, 28, 1], \\\n",
    "                 conv_dims = [4, 4, 1, 1, 32], \\\n",
    "                 pool_dims = [2, 2], \\\n",
    "                 fc1_units = 128, n_classes=10):\n",
    "        '''\n",
    "            ARGUMENTS:\n",
    "            Lists of dimensions for each layer of CNN. Default is MNIST for input.\n",
    "            Convention as follows:\n",
    "            * img_dims = [in_height, in_width, in_channels], dims of input images.\n",
    "            * conv_dims = [conv_ker_ht, conv_ker_wd, conv_str_ht, conv_str_wd, n_conv_filters]\n",
    "            * pool_dims = [pool_ver, pool_hor]. Here stride size = kernel size.\n",
    "            * fc1_units = no. of neurons in fully connected layer.\n",
    "            * n_classes = no. of classes or dim. of output layer.\n",
    "            \n",
    "            \n",
    "        '''\n",
    "        super().__init__()\n",
    "        \n",
    "        #####################\n",
    "        ## HYPERPARAMETERS ##\n",
    "        #####################\n",
    "        \n",
    "        # Input image dimensions\n",
    "        self.in_height = img_dims[0]\n",
    "        self.in_width = img_dims[1]\n",
    "        self.in_channels = img_dims[2]\n",
    "        \n",
    "        # Conv. layer hyperparam.\n",
    "        ## Using 0 padding \n",
    "        self.conv_ker_ht = conv_dims[0]\n",
    "        self.conv_ker_wd = conv_dims[1]\n",
    "        self.conv_str_ht = conv_dims[2]\n",
    "        self.conv_str_wd = conv_dims[3]\n",
    "        self.n_conv_filters = conv_dims[4]\n",
    "        self.conv_out_ht = int((self.in_height-self.conv_ker_ht)/ self.conv_str_ht)+1\n",
    "        self.conv_out_wd = int((self.in_width-self.conv_ker_wd)/ self.conv_str_wd)/+1\n",
    "        \n",
    "        # Pooling layer hyperparam.\n",
    "        ## Using 0 padding, stride size = \"kernel\" size\n",
    "        self.pool_ver = pool_dims[0]\n",
    "        self.pool_hor = pool_dims[1]\n",
    "        \n",
    "        # FC1 layer dim\n",
    "        self.fc1_dim_in = self.n_conv_filters*int(self.conv_out_ht/self.pool_ver)\\\n",
    "                            *int(self.conv_out_wd/self.pool_hor)\n",
    "        self.fc1_units = fc1_units\n",
    "        \n",
    "        # Out (FC2) layer dim (no. of classes)\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        #####################\n",
    "        ##      LAYERS     ##\n",
    "        #####################\n",
    "        \n",
    "        #self.cnn_dim_list = cnn_dim_list # useful? necessary?\n",
    "        '''\n",
    "            CONVOLUTIONAL LAYER\n",
    "            torch.nn.Conv2d(in_channels, out_channels, kernel_size, \\\n",
    "                            stride=1, padding=0, dilation=1, groups=1, \\\n",
    "                            bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "            in_channels and out_channels are ints, not \n",
    "        '''\n",
    "        self.layer_1_conv = nn.Conv2d(in_channels = self.in_channels, \\\n",
    "                                      out_channels = self.n_conv_filters,\\\n",
    "                                      kernel_size = (self.conv_ker_ht, self.conv_ker_wd),\\\n",
    "                                      stride = (self.conv_str_ht, self.conv_str_wd), \\\n",
    "                                      padding=0)\n",
    "        '''\n",
    "            MAXPOOL LAYER\n",
    "            torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, \\\n",
    "                                dilation=1, return_indices=False, ceil_mode=False)\n",
    "        '''\n",
    "        self.layer_2_maxpl = nn.MaxPool2d(kernel_size= (self.pool_ver, self.pool_hor), \\\n",
    "                                          stride = (self.pool_ver, self.pool_hor), padding=0)\n",
    "        self.layer_3_fc = nn.Linear(in_features=self.fc1_dim_in, out_features=self.fc1_units)\n",
    "        self.layer_4_fc = nn.Linear(in_features=self.fc1_units, out_features=self.n_classes)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        X = self.layer_1_conv(X)\n",
    "        X = self.layer_2_maxpl(X)\n",
    "        X = F.relu(self.layer_3_fc(X.reshape(-1,self.fc1_dim_in))) # Flatten images here\n",
    "        X = F.log_softmax(self.layer_4_fc(X), dim =1)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6595186-449a-4164-bd4f-4a99a71be2df",
   "metadata": {},
   "source": [
    "#### Instantiating the model\n",
    "\n",
    "To avoid conflicts with the previous ANN, the CNN model will be called *cnn_model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e3a645cb-6b18-4c08-959e-9ee840677402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refresh model\n",
    "del cnn_model, cnn_loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3c73cdd-e83d-4959-8e26-7c4c01a03013",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "##### Network hyperparameters #####\n",
    "###################################\n",
    "\n",
    "# Input/Final Output\n",
    "n_height = 28\n",
    "n_width = 28\n",
    "n_channels = 1\n",
    "\n",
    "# Conv. layer\n",
    "conv_ker_ht = 4\n",
    "conv_ker_wd = 4\n",
    "conv_n_filters = 32\n",
    "\n",
    "# MaxPool layer\n",
    "pool_ver = 2 \n",
    "pool_hor = 2\n",
    "\n",
    "# Dims of 2 fully connected layers\n",
    "fc1_dim_out = 128\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f8423d9-0a83-4232-90da-7f72ea615d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "cnn_model = CNN(img_dims=[n_height, n_width, n_channels],\\\n",
    "                conv_dims=[conv_ker_ht, conv_ker_wd, 1, 1, conv_n_filters],\\\n",
    "                pool_dims=[pool_ver, pool_hor], \\\n",
    "                fc1_units=fc1_dim_out, n_classes = n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f070d05-0274-43bb-b17f-cf41a7fa74b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function:\n",
    "cnn_loss_fn = nn.CrossEntropyLoss()\n",
    "# Optimizer:\n",
    "optimizer = T.optim.Adam(params = cnn_model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dba7b7-747e-4bcb-be4d-7bbe582755a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Training code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "85fafcf8-4360-46dc-ac78-81726fca3d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1; Loss:     0.1594; Accuracy:      86.23%\n",
      "Epoch: 2; Loss:     0.1445; Accuracy:      94.05%\n",
      "Epoch: 3; Loss:     0.1079; Accuracy:      96.35%\n",
      "Epoch: 4; Loss:     0.0674; Accuracy:      97.52%\n",
      "Epoch: 5; Loss:     0.1086; Accuracy:      98.33%\n",
      "Epoch: 6; Loss:     0.0406; Accuracy:      98.81%\n",
      "Epoch: 7; Loss:     0.0207; Accuracy:      99.19%\n",
      "Epoch: 8; Loss:     0.0171; Accuracy:      99.48%\n",
      "Epoch: 9; Loss:     0.0036; Accuracy:      99.74%\n",
      "Epoch: 10; Loss:     0.0056; Accuracy:      99.88%\n",
      "Training finished. Elapsed time = 0:01:58.675659\n"
     ]
    }
   ],
   "source": [
    "##### TRAINING #####\n",
    "\n",
    "# Initializations\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = len(train_loader)\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "'''\n",
    "# Should normally make the DataLoader() here:\n",
    "train_loader = DataLoader(dataset = Dataset_train, batch_size = batch_size, shuffle = True)\n",
    "'''\n",
    "\n",
    "# Timer init.\n",
    "train_begin_time = datetime.now()\n",
    "\n",
    "# Loop over epochs:\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    train_correct_samples = 0 \n",
    "    val_correct_samples = 0\n",
    "    \n",
    "    # Loop over batches\n",
    "    #for i_batch in range(n_batches):\n",
    "    for i_batch, (batch_x, batch_y) in enumerate(train_loader):\n",
    "        \n",
    "        # Predict labels and compute loss\n",
    "        batch_y_pred = cnn_model(batch_x.reshape(batch_size, n_channels, n_height, n_width)) # CLARIFY.\n",
    "        loss = cnn_loss_fn(batch_y_pred, batch_y) # CLARIFY.\n",
    "        \n",
    "        # Counter no. of correct predictions and current accuracy\n",
    "        predicted_digits = T.argmax(batch_y_pred, dim =1)\n",
    "        batch_correct = (predicted_digits == batch_y).sum().item()\n",
    "        train_correct_samples += batch_correct\n",
    "        current_accuracy = (train_correct_samples*100)/((i_batch+1)*batch_size)\n",
    "        \n",
    "        # Perform one optimization step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "        \n",
    "    # END OF BATCH LOOP\n",
    "    print(f\"Epoch: {epoch+1}; Loss: {loss.item():10.4f}; Accuracy: {current_accuracy:10.2f}%\")\n",
    "    \n",
    "    # Update train loss & accuracy for the epoch\n",
    "    train_losses.append(loss.item())\n",
    "    train_correct.append(train_correct_samples)\n",
    "\n",
    "# END EPOCH LOOP\n",
    "\n",
    "print(f\"Training finished. Elapsed time = {datetime.now()-train_begin_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d8fd6ff3-87fa-4e76-ab45-bb8018172346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28108f75c70>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(10), train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "31ff5179-e814-4e27-a447-0ac5359d2a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28108f80cd0>]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(10), train_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ef0ccb-1452-4f1f-80de-191fc6c8494c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af9f0b40-4c4c-43ba-8a66-d1786a1491c6",
   "metadata": {},
   "source": [
    "#### Validation code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d758f475-03b1-465c-85a4-d446388fccd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done validation on batch 1...\n",
      "Done validation on batch 2...\n",
      "Done validation on batch 3...\n",
      "Done validation on batch 4...\n",
      "Done validation on batch 5...\n",
      "Done validation on batch 6...\n",
      "Done validation on batch 7...\n",
      "Done validation on batch 8...\n",
      "Done validation on batch 9...\n",
      "Done validation on batch 10...\n",
      "Done validation on batch 11...\n",
      "Done validation on batch 12...\n",
      "Done validation on batch 13...\n",
      "Done validation on batch 14...\n",
      "Done validation on batch 15...\n",
      "Done validation on batch 16...\n",
      "Done validation on batch 17...\n",
      "Done validation on batch 18...\n",
      "Done validation on batch 19...\n",
      "Done validation on batch 20...\n",
      "Done validation on batch 21...\n",
      "Done validation on batch 22...\n",
      "Done validation on batch 23...\n",
      "Done validation on batch 24...\n",
      "Done validation on batch 25...\n",
      "Done validation on batch 26...\n",
      "Done validation on batch 27...\n",
      "Done validation on batch 28...\n",
      "Done validation on batch 29...\n",
      "Done validation on batch 30...\n",
      "Accuracy on validation set: 97.1%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Previously\n",
    "val_loader = DataLoader(dataset = Dataset_val, batch_size = batch_size, shuffle = False)\n",
    "'''\n",
    "n_val_batches = len(val_loader)\n",
    "val_losses = []\n",
    "val_correct = []\n",
    "\n",
    "with T.no_grad():\n",
    "    \n",
    "    val_correct_samples = 0\n",
    "\n",
    "    # Validation loop\n",
    "    for i_batch, (batch_x, batch_y) in enumerate(val_loader):\n",
    "        \n",
    "        # Predict labels and compute loss\n",
    "        batch_y_pred = cnn_model(batch_x.reshape(batch_size, n_channels, n_height, n_width)) \n",
    "\n",
    "        # Counter no. of correct predictions and current accuracy\n",
    "        predicted_digits = T.argmax(batch_y_pred, dim =1)\n",
    "        batch_correct = (predicted_digits == batch_y).sum().item()\n",
    "        val_correct_samples += batch_correct\n",
    "        #current_accuracy = train_correct_samples/((i_batch+1)*batch_size)\n",
    "        print(f\"Done validation on batch {i_batch+1}...\")\n",
    "\n",
    "    # END VALIDATION LOOP\n",
    "    accuracy = (100*val_correct_samples)/len(x_val)\n",
    "    print(f\"Accuracy on validation set: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfaa47d-3196-4d49-b8d8-cd6428abbf0d",
   "metadata": {},
   "source": [
    "**Remarks:** This takes slightly less time than the code without data loader and achieves a slightly higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbea0bdf-1db7-4419-a722-dd637e6e9860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
